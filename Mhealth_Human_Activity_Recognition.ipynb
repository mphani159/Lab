{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Download and extract data files\n",
    "def download_and_extract():\n",
    "\turl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00319/MHEALTHDATASET.zip\"\n",
    "\tprint(\"Downloading..\")\n",
    "\tr = requests.get(url)\n",
    "\n",
    "\t# Write into file\n",
    "\topen('MHEALTHDATASET.zip','wb').write(r.content)\n",
    "\n",
    "\t# Extract\n",
    "\tprint('Extracting...')\n",
    "\tzip_h = zipfile.ZipFile('MHEALTHDATASET.zip','r')\n",
    "\tzip_h.extractall()\n",
    "\tzip_h.close()\n",
    "\n",
    "\t# Rename and remove zip\n",
    "\tos.rename('MHEALTHDATASET', 'data')\n",
    "\tos.remove('MHEALTHDATASET.zip')\n",
    "\n",
    "## Read data per subject\n",
    "def read_subject(subject):\n",
    "\t\"\"\" Read measurements from a given subject \"\"\"\n",
    "\tfile_name = 'mHealth_subject' + str(subject) + '.log'\n",
    "\tfile_path = os.path.join('data',file_name)\n",
    "\n",
    "\n",
    "\t# Read file\n",
    "\ttry:\n",
    "\t\tdf = pd.read_csv(file_path, delim_whitespace = True, header = None)\n",
    "\texcept IOError:\n",
    "\t\tprint(\"Data file does not exist!\")\n",
    "\n",
    "\t# Remove data with null class (=0)\n",
    "\tdf = df[df[23] != 0]\n",
    "\n",
    "\treturn df\n",
    "\n",
    "## Rewrite a sequence for a given subject in tensor format\n",
    "def split_by_blocks(df, block_size=100):\n",
    "\t\"\"\" Split data from each subject into blocks of shorter length \"\"\"\n",
    "\n",
    "\t# Channels\n",
    "\tn_channels = df.shape[1]-1\n",
    "\n",
    "\t# Group by labels \n",
    "\tgrps = df.groupby(23)\n",
    "\t\n",
    "\t# Create a list for concatenating\n",
    "\tX_ = []\n",
    "\tY_ = []\n",
    "\n",
    "\t# Loop over groups (labels), reshape to tensor and concatenate\n",
    "\tfor ig in range(1,len(grps)+1,1):\n",
    "\t\tdf_ = grps.get_group(ig)\n",
    "\n",
    "\t\t# Data and targets\n",
    "\t\ty = pd.unique(df_[23].values)\n",
    "\t\tx = df_.drop(23, axis=1).to_numpy()\n",
    "\n",
    "\t\tn_blocks = len(x) // block_size\n",
    "\t\tx = x[:n_blocks*block_size]\n",
    "\t\ty = y[:n_blocks*block_size]\n",
    "\t\t#print(np.shape(x))\n",
    "        #print(x)\n",
    "\t\tx_tensor = x.reshape(-1, block_size, n_channels)\n",
    "\n",
    "\t\t# Append\n",
    "\t\tX_.append(x_tensor)\n",
    "\t\tY_.append(np.array([y]*len(x_tensor), dtype=int).squeeze())\n",
    "\n",
    "\t# Concatenate and return\n",
    "\tX = np.concatenate(X_, axis=0)\n",
    "\tY = np.concatenate(Y_, axis=0)\n",
    "\n",
    "\treturn X, Y\n",
    "\n",
    "## Merge all the subjects and save into file\n",
    "def collect_save_data(subject_count = 10, block_size=100):\n",
    "\t\"\"\" Collects all the data from all the subjects and writes in file \"\"\"\n",
    "\n",
    "\t# Initiate lists\n",
    "\tX_ = []\n",
    "\tY_ = []\n",
    "\tfor s in range(1,subject_count+1):\n",
    "\t\t# Read the data\n",
    "\t\tdf = read_subject(s)\n",
    "    \n",
    "\t#return df\n",
    "\t\t# Split into blocks\n",
    "\t\tx,y = split_by_blocks(df, block_size)\n",
    "\n",
    "\t\t# Add to list\n",
    "\t\tX_.append(x)\n",
    "\t\tY_.append(y)\n",
    "\n",
    "\t# Concatenate and save\n",
    "\tX = np.concatenate(X_, axis=0)\n",
    "\tY = np.concatenate(Y_, axis=0)\n",
    "\n",
    "\t# Save \n",
    "\tnp.save(os.path.join('data','dataX.npy'), X)\n",
    "\tnp.save(os.path.join('data','dataY.npy'), Y)\n",
    "\n",
    "\n",
    "## One-hot encoding\n",
    "def one_hot(labels, n_class = 12):\n",
    "\t\"\"\" One-hot encoding \"\"\"\n",
    "\texpansion = np.eye(n_class)\n",
    "\ty = expansion[:,labels-1].T\n",
    "\n",
    "\treturn y\n",
    "\n",
    "## Standardize\n",
    "def standardize(X):\n",
    "\t\"\"\" Standardize by mean and std for each measurement channel\"\"\"\n",
    "\treturn (X - np.mean(X, axis=0)[None,:,:]) / np.std(X, axis=0)[None,:,:]\n",
    "\n",
    "## Get batches\n",
    "def get_batches(X, y, batch_size = 100):\n",
    "\t\"\"\" Yield batches ffrom data \"\"\"\n",
    "\tn_batches = len(X) // batch_size\n",
    "\tX, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "\t# Loop over batches and yield\n",
    "\tfor b in range(0, len(X), batch_size):\n",
    "\t\tyield X[b:b+batch_size], y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "#from utils.utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances:  3355\n",
      "Length of sequence:  100\n",
      "Number of channels:  23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read \n",
    "X = np.load('./data/dataX.npy')\n",
    "Y = np.load('./data/dataY.npy')\n",
    "\n",
    "print(\"Number of instances: \", X.shape[0])\n",
    "print(\"Length of sequence: \", X.shape[1])\n",
    "print(\"Number of channels: \", X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test\n",
    "X_tr, X_test, Y_tr, Y_test = train_test_split(X,Y, test_size=0.3, stratify=Y, random_state=123)\n",
    "\n",
    "# Standardize\n",
    "X_tr = standardize(X_tr); X_test = standardize(X_test)\n",
    "\n",
    "# Train/validation\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_tr, Y_tr, test_size=0.4, stratify=Y_tr, random_state=456)\n",
    "\n",
    "# One-hot encode\n",
    "y_train = one_hot(Y_train, n_class=12)\n",
    "y_valid = one_hot(Y_valid, n_class=12)\n",
    "y_test = one_hot(Y_test, n_class=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  1408\n",
      "Validaton set size:  940\n",
      "Test set size:  1007\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size: \", len(X_train))\n",
    "print(\"Validaton set size: \", len(X_valid))\n",
    "print(\"Test set size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 400       \n",
    "seq_len = 100       \n",
    "learning_rate = 0.0001\n",
    "epochs = 1000\n",
    "\n",
    "n_classes = 12\n",
    "n_channels = 23\n",
    "\n",
    "# Placeholders\n",
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING CONVOLUTION LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-d629ed1aad33>:3: conv1d (from tensorflow.python.keras.legacy_tf_layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-24-d629ed1aad33>:5: max_pooling1d (from tensorflow.python.keras.legacy_tf_layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling1D instead.\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 100, 23) --> (batch, 50, 46)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=46, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 50, 46) --> (batch, 25, 92)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=92, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 25, 92) --> (batch, 5, 184)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=184, kernel_size=5, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=5, strides=5, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLATTEN AND PASS TO CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-26-61bf95e11eb1>:7: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(max_pool_3, (-1, 5*184))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN THE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000 Iteration: 5 Train loss: 2.531578 Train acc: 0.107500\n",
      "Epoch: 3/1000 Iteration: 10 Train loss: 2.398342 Train acc: 0.115000\n",
      "Epoch: 3/1000 Iteration: 10 Validation loss: 2.275611 Validation acc: 0.101250\n",
      "Epoch: 4/1000 Iteration: 15 Train loss: 2.357396 Train acc: 0.152500\n",
      "Epoch: 6/1000 Iteration: 20 Train loss: 2.183769 Train acc: 0.215000\n",
      "Epoch: 6/1000 Iteration: 20 Validation loss: 2.143206 Validation acc: 0.235000\n",
      "Epoch: 8/1000 Iteration: 25 Train loss: 2.201128 Train acc: 0.245000\n",
      "Epoch: 9/1000 Iteration: 30 Train loss: 2.066445 Train acc: 0.302500\n",
      "Epoch: 9/1000 Iteration: 30 Validation loss: 2.025039 Validation acc: 0.310000\n",
      "Epoch: 11/1000 Iteration: 35 Train loss: 2.001466 Train acc: 0.335000\n",
      "Epoch: 13/1000 Iteration: 40 Train loss: 2.023512 Train acc: 0.332500\n",
      "Epoch: 13/1000 Iteration: 40 Validation loss: 1.909965 Validation acc: 0.345000\n",
      "Epoch: 14/1000 Iteration: 45 Train loss: 1.938154 Train acc: 0.325000\n",
      "Epoch: 16/1000 Iteration: 50 Train loss: 1.825171 Train acc: 0.410000\n",
      "Epoch: 16/1000 Iteration: 50 Validation loss: 1.799444 Validation acc: 0.436250\n",
      "Epoch: 18/1000 Iteration: 55 Train loss: 1.782647 Train acc: 0.420000\n",
      "Epoch: 19/1000 Iteration: 60 Train loss: 1.753701 Train acc: 0.442500\n",
      "Epoch: 19/1000 Iteration: 60 Validation loss: 1.689951 Validation acc: 0.517500\n",
      "Epoch: 21/1000 Iteration: 65 Train loss: 1.643875 Train acc: 0.522500\n",
      "Epoch: 23/1000 Iteration: 70 Train loss: 1.661192 Train acc: 0.460000\n",
      "Epoch: 23/1000 Iteration: 70 Validation loss: 1.583602 Validation acc: 0.565000\n",
      "Epoch: 24/1000 Iteration: 75 Train loss: 1.573751 Train acc: 0.532500\n",
      "Epoch: 26/1000 Iteration: 80 Train loss: 1.482558 Train acc: 0.590000\n",
      "Epoch: 26/1000 Iteration: 80 Validation loss: 1.478000 Validation acc: 0.623750\n",
      "Epoch: 28/1000 Iteration: 85 Train loss: 1.504872 Train acc: 0.585000\n",
      "Epoch: 29/1000 Iteration: 90 Train loss: 1.420284 Train acc: 0.600000\n",
      "Epoch: 29/1000 Iteration: 90 Validation loss: 1.371240 Validation acc: 0.658750\n",
      "Epoch: 31/1000 Iteration: 95 Train loss: 1.315908 Train acc: 0.642500\n",
      "Epoch: 33/1000 Iteration: 100 Train loss: 1.333201 Train acc: 0.625000\n",
      "Epoch: 33/1000 Iteration: 100 Validation loss: 1.266082 Validation acc: 0.695000\n",
      "Epoch: 34/1000 Iteration: 105 Train loss: 1.270329 Train acc: 0.680000\n",
      "Epoch: 36/1000 Iteration: 110 Train loss: 1.149220 Train acc: 0.667500\n",
      "Epoch: 36/1000 Iteration: 110 Validation loss: 1.163993 Validation acc: 0.737500\n",
      "Epoch: 38/1000 Iteration: 115 Train loss: 1.149022 Train acc: 0.687500\n",
      "Epoch: 39/1000 Iteration: 120 Train loss: 1.123662 Train acc: 0.675000\n",
      "Epoch: 39/1000 Iteration: 120 Validation loss: 1.064718 Validation acc: 0.763750\n",
      "Epoch: 41/1000 Iteration: 125 Train loss: 0.995223 Train acc: 0.765000\n",
      "Epoch: 43/1000 Iteration: 130 Train loss: 1.038178 Train acc: 0.712500\n",
      "Epoch: 43/1000 Iteration: 130 Validation loss: 0.972052 Validation acc: 0.783750\n",
      "Epoch: 44/1000 Iteration: 135 Train loss: 0.935396 Train acc: 0.785000\n",
      "Epoch: 46/1000 Iteration: 140 Train loss: 0.900477 Train acc: 0.757500\n",
      "Epoch: 46/1000 Iteration: 140 Validation loss: 0.888785 Validation acc: 0.798750\n",
      "Epoch: 48/1000 Iteration: 145 Train loss: 0.914402 Train acc: 0.765000\n",
      "Epoch: 49/1000 Iteration: 150 Train loss: 0.836472 Train acc: 0.810000\n",
      "Epoch: 49/1000 Iteration: 150 Validation loss: 0.810378 Validation acc: 0.820000\n",
      "Epoch: 51/1000 Iteration: 155 Train loss: 0.780587 Train acc: 0.797500\n",
      "Epoch: 53/1000 Iteration: 160 Train loss: 0.824634 Train acc: 0.795000\n",
      "Epoch: 53/1000 Iteration: 160 Validation loss: 0.742481 Validation acc: 0.837500\n",
      "Epoch: 54/1000 Iteration: 165 Train loss: 0.722201 Train acc: 0.845000\n",
      "Epoch: 56/1000 Iteration: 170 Train loss: 0.712595 Train acc: 0.812500\n",
      "Epoch: 56/1000 Iteration: 170 Validation loss: 0.678656 Validation acc: 0.856250\n",
      "Epoch: 58/1000 Iteration: 175 Train loss: 0.710989 Train acc: 0.800000\n",
      "Epoch: 59/1000 Iteration: 180 Train loss: 0.673162 Train acc: 0.827500\n",
      "Epoch: 59/1000 Iteration: 180 Validation loss: 0.623565 Validation acc: 0.861250\n",
      "Epoch: 61/1000 Iteration: 185 Train loss: 0.603390 Train acc: 0.852500\n",
      "Epoch: 63/1000 Iteration: 190 Train loss: 0.611570 Train acc: 0.827500\n",
      "Epoch: 63/1000 Iteration: 190 Validation loss: 0.570118 Validation acc: 0.873750\n",
      "Epoch: 64/1000 Iteration: 195 Train loss: 0.526144 Train acc: 0.890000\n",
      "Epoch: 66/1000 Iteration: 200 Train loss: 0.538189 Train acc: 0.857500\n",
      "Epoch: 66/1000 Iteration: 200 Validation loss: 0.527324 Validation acc: 0.880000\n",
      "Epoch: 68/1000 Iteration: 205 Train loss: 0.600755 Train acc: 0.845000\n",
      "Epoch: 69/1000 Iteration: 210 Train loss: 0.478203 Train acc: 0.905000\n",
      "Epoch: 69/1000 Iteration: 210 Validation loss: 0.482128 Validation acc: 0.896250\n",
      "Epoch: 71/1000 Iteration: 215 Train loss: 0.465161 Train acc: 0.890000\n",
      "Epoch: 73/1000 Iteration: 220 Train loss: 0.491679 Train acc: 0.872500\n",
      "Epoch: 73/1000 Iteration: 220 Validation loss: 0.446395 Validation acc: 0.896250\n",
      "Epoch: 74/1000 Iteration: 225 Train loss: 0.422371 Train acc: 0.905000\n",
      "Epoch: 76/1000 Iteration: 230 Train loss: 0.429998 Train acc: 0.897500\n",
      "Epoch: 76/1000 Iteration: 230 Validation loss: 0.409402 Validation acc: 0.902500\n",
      "Epoch: 78/1000 Iteration: 235 Train loss: 0.478099 Train acc: 0.875000\n",
      "Epoch: 79/1000 Iteration: 240 Train loss: 0.385111 Train acc: 0.915000\n",
      "Epoch: 79/1000 Iteration: 240 Validation loss: 0.378883 Validation acc: 0.911250\n",
      "Epoch: 81/1000 Iteration: 245 Train loss: 0.385601 Train acc: 0.895000\n",
      "Epoch: 83/1000 Iteration: 250 Train loss: 0.357968 Train acc: 0.900000\n",
      "Epoch: 83/1000 Iteration: 250 Validation loss: 0.348172 Validation acc: 0.923750\n",
      "Epoch: 84/1000 Iteration: 255 Train loss: 0.312221 Train acc: 0.942500\n",
      "Epoch: 86/1000 Iteration: 260 Train loss: 0.346661 Train acc: 0.907500\n",
      "Epoch: 86/1000 Iteration: 260 Validation loss: 0.321430 Validation acc: 0.927500\n",
      "Epoch: 88/1000 Iteration: 265 Train loss: 0.371555 Train acc: 0.895000\n",
      "Epoch: 89/1000 Iteration: 270 Train loss: 0.290052 Train acc: 0.937500\n",
      "Epoch: 89/1000 Iteration: 270 Validation loss: 0.303379 Validation acc: 0.927500\n",
      "Epoch: 91/1000 Iteration: 275 Train loss: 0.278300 Train acc: 0.937500\n",
      "Epoch: 93/1000 Iteration: 280 Train loss: 0.300252 Train acc: 0.927500\n",
      "Epoch: 93/1000 Iteration: 280 Validation loss: 0.276571 Validation acc: 0.945000\n",
      "Epoch: 94/1000 Iteration: 285 Train loss: 0.259019 Train acc: 0.940000\n",
      "Epoch: 96/1000 Iteration: 290 Train loss: 0.276423 Train acc: 0.937500\n",
      "Epoch: 96/1000 Iteration: 290 Validation loss: 0.262505 Validation acc: 0.947500\n",
      "Epoch: 98/1000 Iteration: 295 Train loss: 0.261177 Train acc: 0.942500\n",
      "Epoch: 99/1000 Iteration: 300 Train loss: 0.217502 Train acc: 0.952500\n",
      "Epoch: 99/1000 Iteration: 300 Validation loss: 0.240824 Validation acc: 0.953750\n",
      "Epoch: 101/1000 Iteration: 305 Train loss: 0.230555 Train acc: 0.947500\n",
      "Epoch: 103/1000 Iteration: 310 Train loss: 0.246595 Train acc: 0.932500\n",
      "Epoch: 103/1000 Iteration: 310 Validation loss: 0.224799 Validation acc: 0.958750\n",
      "Epoch: 104/1000 Iteration: 315 Train loss: 0.206503 Train acc: 0.955000\n",
      "Epoch: 106/1000 Iteration: 320 Train loss: 0.194578 Train acc: 0.977500\n",
      "Epoch: 106/1000 Iteration: 320 Validation loss: 0.209427 Validation acc: 0.962500\n",
      "Epoch: 108/1000 Iteration: 325 Train loss: 0.220705 Train acc: 0.942500\n",
      "Epoch: 109/1000 Iteration: 330 Train loss: 0.190749 Train acc: 0.965000\n",
      "Epoch: 109/1000 Iteration: 330 Validation loss: 0.195620 Validation acc: 0.962500\n",
      "Epoch: 111/1000 Iteration: 335 Train loss: 0.195128 Train acc: 0.955000\n",
      "Epoch: 113/1000 Iteration: 340 Train loss: 0.207688 Train acc: 0.957500\n",
      "Epoch: 113/1000 Iteration: 340 Validation loss: 0.183773 Validation acc: 0.967500\n",
      "Epoch: 114/1000 Iteration: 345 Train loss: 0.185780 Train acc: 0.952500\n",
      "Epoch: 116/1000 Iteration: 350 Train loss: 0.180446 Train acc: 0.957500\n",
      "Epoch: 116/1000 Iteration: 350 Validation loss: 0.175752 Validation acc: 0.967500\n",
      "Epoch: 118/1000 Iteration: 355 Train loss: 0.199075 Train acc: 0.945000\n",
      "Epoch: 119/1000 Iteration: 360 Train loss: 0.153699 Train acc: 0.972500\n",
      "Epoch: 119/1000 Iteration: 360 Validation loss: 0.165241 Validation acc: 0.967500\n",
      "Epoch: 121/1000 Iteration: 365 Train loss: 0.170310 Train acc: 0.965000\n",
      "Epoch: 123/1000 Iteration: 370 Train loss: 0.155380 Train acc: 0.965000\n",
      "Epoch: 123/1000 Iteration: 370 Validation loss: 0.160547 Validation acc: 0.968750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124/1000 Iteration: 375 Train loss: 0.138322 Train acc: 0.975000\n",
      "Epoch: 126/1000 Iteration: 380 Train loss: 0.158017 Train acc: 0.965000\n",
      "Epoch: 126/1000 Iteration: 380 Validation loss: 0.146471 Validation acc: 0.972500\n",
      "Epoch: 128/1000 Iteration: 385 Train loss: 0.141209 Train acc: 0.967500\n",
      "Epoch: 129/1000 Iteration: 390 Train loss: 0.135942 Train acc: 0.972500\n",
      "Epoch: 129/1000 Iteration: 390 Validation loss: 0.140583 Validation acc: 0.972500\n",
      "Epoch: 131/1000 Iteration: 395 Train loss: 0.118072 Train acc: 0.982500\n",
      "Epoch: 133/1000 Iteration: 400 Train loss: 0.142891 Train acc: 0.967500\n",
      "Epoch: 133/1000 Iteration: 400 Validation loss: 0.136256 Validation acc: 0.973750\n",
      "Epoch: 134/1000 Iteration: 405 Train loss: 0.107045 Train acc: 0.980000\n",
      "Epoch: 136/1000 Iteration: 410 Train loss: 0.118913 Train acc: 0.980000\n",
      "Epoch: 136/1000 Iteration: 410 Validation loss: 0.126788 Validation acc: 0.976250\n",
      "Epoch: 138/1000 Iteration: 415 Train loss: 0.122609 Train acc: 0.977500\n",
      "Epoch: 139/1000 Iteration: 420 Train loss: 0.122609 Train acc: 0.970000\n",
      "Epoch: 139/1000 Iteration: 420 Validation loss: 0.121937 Validation acc: 0.976250\n",
      "Epoch: 141/1000 Iteration: 425 Train loss: 0.106569 Train acc: 0.982500\n",
      "Epoch: 143/1000 Iteration: 430 Train loss: 0.116516 Train acc: 0.977500\n",
      "Epoch: 143/1000 Iteration: 430 Validation loss: 0.116537 Validation acc: 0.976250\n",
      "Epoch: 144/1000 Iteration: 435 Train loss: 0.096508 Train acc: 0.982500\n",
      "Epoch: 146/1000 Iteration: 440 Train loss: 0.097727 Train acc: 0.990000\n",
      "Epoch: 146/1000 Iteration: 440 Validation loss: 0.112095 Validation acc: 0.975000\n",
      "Epoch: 148/1000 Iteration: 445 Train loss: 0.110955 Train acc: 0.977500\n",
      "Epoch: 149/1000 Iteration: 450 Train loss: 0.080828 Train acc: 0.990000\n",
      "Epoch: 149/1000 Iteration: 450 Validation loss: 0.106923 Validation acc: 0.978750\n",
      "Epoch: 151/1000 Iteration: 455 Train loss: 0.085608 Train acc: 0.987500\n",
      "Epoch: 153/1000 Iteration: 460 Train loss: 0.093613 Train acc: 0.987500\n",
      "Epoch: 153/1000 Iteration: 460 Validation loss: 0.102923 Validation acc: 0.978750\n",
      "Epoch: 154/1000 Iteration: 465 Train loss: 0.067728 Train acc: 0.992500\n",
      "Epoch: 156/1000 Iteration: 470 Train loss: 0.075134 Train acc: 0.995000\n",
      "Epoch: 156/1000 Iteration: 470 Validation loss: 0.098626 Validation acc: 0.980000\n",
      "Epoch: 158/1000 Iteration: 475 Train loss: 0.093793 Train acc: 0.977500\n",
      "Epoch: 159/1000 Iteration: 480 Train loss: 0.070555 Train acc: 0.987500\n",
      "Epoch: 159/1000 Iteration: 480 Validation loss: 0.095740 Validation acc: 0.977500\n",
      "Epoch: 161/1000 Iteration: 485 Train loss: 0.084104 Train acc: 0.987500\n",
      "Epoch: 163/1000 Iteration: 490 Train loss: 0.080675 Train acc: 0.987500\n",
      "Epoch: 163/1000 Iteration: 490 Validation loss: 0.094718 Validation acc: 0.976250\n",
      "Epoch: 164/1000 Iteration: 495 Train loss: 0.069607 Train acc: 0.990000\n",
      "Epoch: 166/1000 Iteration: 500 Train loss: 0.070468 Train acc: 0.992500\n",
      "Epoch: 166/1000 Iteration: 500 Validation loss: 0.089111 Validation acc: 0.981250\n",
      "Epoch: 168/1000 Iteration: 505 Train loss: 0.092345 Train acc: 0.977500\n",
      "Epoch: 169/1000 Iteration: 510 Train loss: 0.060965 Train acc: 0.987500\n",
      "Epoch: 169/1000 Iteration: 510 Validation loss: 0.089205 Validation acc: 0.977500\n",
      "Epoch: 171/1000 Iteration: 515 Train loss: 0.063410 Train acc: 0.995000\n",
      "Epoch: 173/1000 Iteration: 520 Train loss: 0.077316 Train acc: 0.987500\n",
      "Epoch: 173/1000 Iteration: 520 Validation loss: 0.083305 Validation acc: 0.983750\n",
      "Epoch: 174/1000 Iteration: 525 Train loss: 0.058633 Train acc: 0.997500\n",
      "Epoch: 176/1000 Iteration: 530 Train loss: 0.054376 Train acc: 0.992500\n",
      "Epoch: 176/1000 Iteration: 530 Validation loss: 0.085137 Validation acc: 0.978750\n",
      "Epoch: 178/1000 Iteration: 535 Train loss: 0.060365 Train acc: 0.990000\n",
      "Epoch: 179/1000 Iteration: 540 Train loss: 0.049366 Train acc: 0.995000\n",
      "Epoch: 179/1000 Iteration: 540 Validation loss: 0.077949 Validation acc: 0.985000\n",
      "Epoch: 181/1000 Iteration: 545 Train loss: 0.057628 Train acc: 0.995000\n",
      "Epoch: 183/1000 Iteration: 550 Train loss: 0.058221 Train acc: 0.992500\n",
      "Epoch: 183/1000 Iteration: 550 Validation loss: 0.078610 Validation acc: 0.983750\n",
      "Epoch: 184/1000 Iteration: 555 Train loss: 0.053454 Train acc: 0.990000\n",
      "Epoch: 186/1000 Iteration: 560 Train loss: 0.052211 Train acc: 0.992500\n",
      "Epoch: 186/1000 Iteration: 560 Validation loss: 0.075882 Validation acc: 0.983750\n",
      "Epoch: 188/1000 Iteration: 565 Train loss: 0.054238 Train acc: 0.992500\n",
      "Epoch: 189/1000 Iteration: 570 Train loss: 0.046366 Train acc: 0.997500\n",
      "Epoch: 189/1000 Iteration: 570 Validation loss: 0.071633 Validation acc: 0.986250\n",
      "Epoch: 191/1000 Iteration: 575 Train loss: 0.055922 Train acc: 0.992500\n",
      "Epoch: 193/1000 Iteration: 580 Train loss: 0.047090 Train acc: 0.990000\n",
      "Epoch: 193/1000 Iteration: 580 Validation loss: 0.069399 Validation acc: 0.986250\n",
      "Epoch: 194/1000 Iteration: 585 Train loss: 0.051168 Train acc: 0.992500\n",
      "Epoch: 196/1000 Iteration: 590 Train loss: 0.044371 Train acc: 0.995000\n",
      "Epoch: 196/1000 Iteration: 590 Validation loss: 0.068662 Validation acc: 0.986250\n",
      "Epoch: 198/1000 Iteration: 595 Train loss: 0.059653 Train acc: 0.982500\n",
      "Epoch: 199/1000 Iteration: 600 Train loss: 0.038035 Train acc: 0.997500\n",
      "Epoch: 199/1000 Iteration: 600 Validation loss: 0.066620 Validation acc: 0.986250\n",
      "Epoch: 201/1000 Iteration: 605 Train loss: 0.045655 Train acc: 0.995000\n",
      "Epoch: 203/1000 Iteration: 610 Train loss: 0.053330 Train acc: 0.992500\n",
      "Epoch: 203/1000 Iteration: 610 Validation loss: 0.064664 Validation acc: 0.986250\n",
      "Epoch: 204/1000 Iteration: 615 Train loss: 0.037179 Train acc: 0.995000\n",
      "Epoch: 206/1000 Iteration: 620 Train loss: 0.042509 Train acc: 0.997500\n",
      "Epoch: 206/1000 Iteration: 620 Validation loss: 0.065555 Validation acc: 0.986250\n",
      "Epoch: 208/1000 Iteration: 625 Train loss: 0.037729 Train acc: 0.997500\n",
      "Epoch: 209/1000 Iteration: 630 Train loss: 0.041358 Train acc: 0.992500\n",
      "Epoch: 209/1000 Iteration: 630 Validation loss: 0.063825 Validation acc: 0.986250\n",
      "Epoch: 211/1000 Iteration: 635 Train loss: 0.049258 Train acc: 0.990000\n",
      "Epoch: 213/1000 Iteration: 640 Train loss: 0.054509 Train acc: 0.987500\n",
      "Epoch: 213/1000 Iteration: 640 Validation loss: 0.061711 Validation acc: 0.986250\n",
      "Epoch: 214/1000 Iteration: 645 Train loss: 0.033040 Train acc: 0.997500\n",
      "Epoch: 216/1000 Iteration: 650 Train loss: 0.033454 Train acc: 0.997500\n",
      "Epoch: 216/1000 Iteration: 650 Validation loss: 0.060552 Validation acc: 0.986250\n",
      "Epoch: 218/1000 Iteration: 655 Train loss: 0.040696 Train acc: 0.995000\n",
      "Epoch: 219/1000 Iteration: 660 Train loss: 0.030284 Train acc: 1.000000\n",
      "Epoch: 219/1000 Iteration: 660 Validation loss: 0.059269 Validation acc: 0.987500\n",
      "Epoch: 221/1000 Iteration: 665 Train loss: 0.034073 Train acc: 0.992500\n",
      "Epoch: 223/1000 Iteration: 670 Train loss: 0.039323 Train acc: 0.992500\n",
      "Epoch: 223/1000 Iteration: 670 Validation loss: 0.060558 Validation acc: 0.986250\n",
      "Epoch: 224/1000 Iteration: 675 Train loss: 0.029270 Train acc: 0.997500\n",
      "Epoch: 226/1000 Iteration: 680 Train loss: 0.033327 Train acc: 1.000000\n",
      "Epoch: 226/1000 Iteration: 680 Validation loss: 0.056014 Validation acc: 0.987500\n",
      "Epoch: 228/1000 Iteration: 685 Train loss: 0.036266 Train acc: 0.995000\n",
      "Epoch: 229/1000 Iteration: 690 Train loss: 0.029097 Train acc: 1.000000\n",
      "Epoch: 229/1000 Iteration: 690 Validation loss: 0.058041 Validation acc: 0.987500\n",
      "Epoch: 231/1000 Iteration: 695 Train loss: 0.032189 Train acc: 0.992500\n",
      "Epoch: 233/1000 Iteration: 700 Train loss: 0.030598 Train acc: 0.995000\n",
      "Epoch: 233/1000 Iteration: 700 Validation loss: 0.054389 Validation acc: 0.987500\n",
      "Epoch: 234/1000 Iteration: 705 Train loss: 0.032325 Train acc: 0.990000\n",
      "Epoch: 236/1000 Iteration: 710 Train loss: 0.028928 Train acc: 0.997500\n",
      "Epoch: 236/1000 Iteration: 710 Validation loss: 0.056608 Validation acc: 0.986250\n",
      "Epoch: 238/1000 Iteration: 715 Train loss: 0.032894 Train acc: 0.997500\n",
      "Epoch: 239/1000 Iteration: 720 Train loss: 0.026352 Train acc: 0.997500\n",
      "Epoch: 239/1000 Iteration: 720 Validation loss: 0.052613 Validation acc: 0.987500\n",
      "Epoch: 241/1000 Iteration: 725 Train loss: 0.034342 Train acc: 0.995000\n",
      "Epoch: 243/1000 Iteration: 730 Train loss: 0.035019 Train acc: 0.995000\n",
      "Epoch: 243/1000 Iteration: 730 Validation loss: 0.055513 Validation acc: 0.987500\n",
      "Epoch: 244/1000 Iteration: 735 Train loss: 0.027799 Train acc: 0.997500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 246/1000 Iteration: 740 Train loss: 0.025101 Train acc: 1.000000\n",
      "Epoch: 246/1000 Iteration: 740 Validation loss: 0.051221 Validation acc: 0.987500\n",
      "Epoch: 248/1000 Iteration: 745 Train loss: 0.033092 Train acc: 0.995000\n",
      "Epoch: 249/1000 Iteration: 750 Train loss: 0.020234 Train acc: 1.000000\n",
      "Epoch: 249/1000 Iteration: 750 Validation loss: 0.051563 Validation acc: 0.988750\n",
      "Epoch: 251/1000 Iteration: 755 Train loss: 0.020615 Train acc: 1.000000\n",
      "Epoch: 253/1000 Iteration: 760 Train loss: 0.037252 Train acc: 0.985000\n",
      "Epoch: 253/1000 Iteration: 760 Validation loss: 0.049590 Validation acc: 0.988750\n",
      "Epoch: 254/1000 Iteration: 765 Train loss: 0.030248 Train acc: 0.995000\n",
      "Epoch: 256/1000 Iteration: 770 Train loss: 0.028015 Train acc: 0.992500\n",
      "Epoch: 256/1000 Iteration: 770 Validation loss: 0.048690 Validation acc: 0.990000\n",
      "Epoch: 258/1000 Iteration: 775 Train loss: 0.023812 Train acc: 1.000000\n",
      "Epoch: 259/1000 Iteration: 780 Train loss: 0.021219 Train acc: 0.995000\n",
      "Epoch: 259/1000 Iteration: 780 Validation loss: 0.051218 Validation acc: 0.986250\n",
      "Epoch: 261/1000 Iteration: 785 Train loss: 0.027396 Train acc: 0.992500\n",
      "Epoch: 263/1000 Iteration: 790 Train loss: 0.024298 Train acc: 0.997500\n",
      "Epoch: 263/1000 Iteration: 790 Validation loss: 0.047286 Validation acc: 0.991250\n",
      "Epoch: 264/1000 Iteration: 795 Train loss: 0.024138 Train acc: 0.997500\n",
      "Epoch: 266/1000 Iteration: 800 Train loss: 0.023399 Train acc: 1.000000\n",
      "Epoch: 266/1000 Iteration: 800 Validation loss: 0.048196 Validation acc: 0.988750\n",
      "Epoch: 268/1000 Iteration: 805 Train loss: 0.019808 Train acc: 1.000000\n",
      "Epoch: 269/1000 Iteration: 810 Train loss: 0.018012 Train acc: 1.000000\n",
      "Epoch: 269/1000 Iteration: 810 Validation loss: 0.048090 Validation acc: 0.988750\n",
      "Epoch: 271/1000 Iteration: 815 Train loss: 0.023923 Train acc: 0.997500\n",
      "Epoch: 273/1000 Iteration: 820 Train loss: 0.029169 Train acc: 0.992500\n",
      "Epoch: 273/1000 Iteration: 820 Validation loss: 0.046951 Validation acc: 0.990000\n",
      "Epoch: 274/1000 Iteration: 825 Train loss: 0.020015 Train acc: 0.997500\n",
      "Epoch: 276/1000 Iteration: 830 Train loss: 0.018432 Train acc: 1.000000\n",
      "Epoch: 276/1000 Iteration: 830 Validation loss: 0.047873 Validation acc: 0.988750\n",
      "Epoch: 278/1000 Iteration: 835 Train loss: 0.019064 Train acc: 1.000000\n",
      "Epoch: 279/1000 Iteration: 840 Train loss: 0.016800 Train acc: 0.997500\n",
      "Epoch: 279/1000 Iteration: 840 Validation loss: 0.045098 Validation acc: 0.990000\n",
      "Epoch: 281/1000 Iteration: 845 Train loss: 0.019072 Train acc: 1.000000\n",
      "Epoch: 283/1000 Iteration: 850 Train loss: 0.026350 Train acc: 0.995000\n",
      "Epoch: 283/1000 Iteration: 850 Validation loss: 0.044236 Validation acc: 0.990000\n",
      "Epoch: 284/1000 Iteration: 855 Train loss: 0.023242 Train acc: 0.995000\n",
      "Epoch: 286/1000 Iteration: 860 Train loss: 0.017297 Train acc: 1.000000\n",
      "Epoch: 286/1000 Iteration: 860 Validation loss: 0.046699 Validation acc: 0.987500\n",
      "Epoch: 288/1000 Iteration: 865 Train loss: 0.021152 Train acc: 0.997500\n",
      "Epoch: 289/1000 Iteration: 870 Train loss: 0.015323 Train acc: 1.000000\n",
      "Epoch: 289/1000 Iteration: 870 Validation loss: 0.043537 Validation acc: 0.988750\n",
      "Epoch: 291/1000 Iteration: 875 Train loss: 0.018713 Train acc: 0.997500\n",
      "Epoch: 293/1000 Iteration: 880 Train loss: 0.019525 Train acc: 0.997500\n",
      "Epoch: 293/1000 Iteration: 880 Validation loss: 0.042812 Validation acc: 0.991250\n",
      "Epoch: 294/1000 Iteration: 885 Train loss: 0.019351 Train acc: 0.997500\n",
      "Epoch: 296/1000 Iteration: 890 Train loss: 0.018200 Train acc: 0.997500\n",
      "Epoch: 296/1000 Iteration: 890 Validation loss: 0.043009 Validation acc: 0.988750\n",
      "Epoch: 298/1000 Iteration: 895 Train loss: 0.015516 Train acc: 0.997500\n",
      "Epoch: 299/1000 Iteration: 900 Train loss: 0.010994 Train acc: 1.000000\n",
      "Epoch: 299/1000 Iteration: 900 Validation loss: 0.044689 Validation acc: 0.988750\n",
      "Epoch: 301/1000 Iteration: 905 Train loss: 0.014482 Train acc: 1.000000\n",
      "Epoch: 303/1000 Iteration: 910 Train loss: 0.022966 Train acc: 0.992500\n",
      "Epoch: 303/1000 Iteration: 910 Validation loss: 0.042801 Validation acc: 0.990000\n",
      "Epoch: 304/1000 Iteration: 915 Train loss: 0.011073 Train acc: 1.000000\n",
      "Epoch: 306/1000 Iteration: 920 Train loss: 0.018011 Train acc: 0.997500\n",
      "Epoch: 306/1000 Iteration: 920 Validation loss: 0.041985 Validation acc: 0.990000\n",
      "Epoch: 308/1000 Iteration: 925 Train loss: 0.014452 Train acc: 1.000000\n",
      "Epoch: 309/1000 Iteration: 930 Train loss: 0.016979 Train acc: 0.995000\n",
      "Epoch: 309/1000 Iteration: 930 Validation loss: 0.041693 Validation acc: 0.988750\n",
      "Epoch: 311/1000 Iteration: 935 Train loss: 0.020444 Train acc: 0.997500\n",
      "Epoch: 313/1000 Iteration: 940 Train loss: 0.017303 Train acc: 0.997500\n",
      "Epoch: 313/1000 Iteration: 940 Validation loss: 0.039836 Validation acc: 0.990000\n",
      "Epoch: 314/1000 Iteration: 945 Train loss: 0.012424 Train acc: 1.000000\n",
      "Epoch: 316/1000 Iteration: 950 Train loss: 0.015176 Train acc: 1.000000\n",
      "Epoch: 316/1000 Iteration: 950 Validation loss: 0.040487 Validation acc: 0.988750\n",
      "Epoch: 318/1000 Iteration: 955 Train loss: 0.019040 Train acc: 0.997500\n",
      "Epoch: 319/1000 Iteration: 960 Train loss: 0.010126 Train acc: 1.000000\n",
      "Epoch: 319/1000 Iteration: 960 Validation loss: 0.040158 Validation acc: 0.990000\n",
      "Epoch: 321/1000 Iteration: 965 Train loss: 0.014471 Train acc: 1.000000\n",
      "Epoch: 323/1000 Iteration: 970 Train loss: 0.017904 Train acc: 0.997500\n",
      "Epoch: 323/1000 Iteration: 970 Validation loss: 0.041072 Validation acc: 0.988750\n",
      "Epoch: 324/1000 Iteration: 975 Train loss: 0.012903 Train acc: 1.000000\n",
      "Epoch: 326/1000 Iteration: 980 Train loss: 0.010156 Train acc: 1.000000\n",
      "Epoch: 326/1000 Iteration: 980 Validation loss: 0.038084 Validation acc: 0.991250\n",
      "Epoch: 328/1000 Iteration: 985 Train loss: 0.020478 Train acc: 0.997500\n",
      "Epoch: 329/1000 Iteration: 990 Train loss: 0.013006 Train acc: 0.997500\n",
      "Epoch: 329/1000 Iteration: 990 Validation loss: 0.039714 Validation acc: 0.988750\n",
      "Epoch: 331/1000 Iteration: 995 Train loss: 0.011805 Train acc: 1.000000\n",
      "Epoch: 333/1000 Iteration: 1000 Train loss: 0.015587 Train acc: 0.997500\n",
      "Epoch: 333/1000 Iteration: 1000 Validation loss: 0.040665 Validation acc: 0.988750\n",
      "Epoch: 334/1000 Iteration: 1005 Train loss: 0.015844 Train acc: 0.997500\n",
      "Epoch: 336/1000 Iteration: 1010 Train loss: 0.013534 Train acc: 1.000000\n",
      "Epoch: 336/1000 Iteration: 1010 Validation loss: 0.038536 Validation acc: 0.988750\n",
      "Epoch: 338/1000 Iteration: 1015 Train loss: 0.015572 Train acc: 0.997500\n",
      "Epoch: 339/1000 Iteration: 1020 Train loss: 0.010204 Train acc: 1.000000\n",
      "Epoch: 339/1000 Iteration: 1020 Validation loss: 0.037237 Validation acc: 0.992500\n",
      "Epoch: 341/1000 Iteration: 1025 Train loss: 0.011958 Train acc: 1.000000\n",
      "Epoch: 343/1000 Iteration: 1030 Train loss: 0.010868 Train acc: 1.000000\n",
      "Epoch: 343/1000 Iteration: 1030 Validation loss: 0.041520 Validation acc: 0.988750\n",
      "Epoch: 344/1000 Iteration: 1035 Train loss: 0.008835 Train acc: 1.000000\n",
      "Epoch: 346/1000 Iteration: 1040 Train loss: 0.009277 Train acc: 1.000000\n",
      "Epoch: 346/1000 Iteration: 1040 Validation loss: 0.037887 Validation acc: 0.990000\n",
      "Epoch: 348/1000 Iteration: 1045 Train loss: 0.011393 Train acc: 1.000000\n",
      "Epoch: 349/1000 Iteration: 1050 Train loss: 0.009950 Train acc: 1.000000\n",
      "Epoch: 349/1000 Iteration: 1050 Validation loss: 0.037292 Validation acc: 0.991250\n",
      "Epoch: 351/1000 Iteration: 1055 Train loss: 0.008515 Train acc: 1.000000\n",
      "Epoch: 353/1000 Iteration: 1060 Train loss: 0.008354 Train acc: 1.000000\n",
      "Epoch: 353/1000 Iteration: 1060 Validation loss: 0.039112 Validation acc: 0.988750\n",
      "Epoch: 354/1000 Iteration: 1065 Train loss: 0.008127 Train acc: 1.000000\n",
      "Epoch: 356/1000 Iteration: 1070 Train loss: 0.009088 Train acc: 1.000000\n",
      "Epoch: 356/1000 Iteration: 1070 Validation loss: 0.037762 Validation acc: 0.988750\n",
      "Epoch: 358/1000 Iteration: 1075 Train loss: 0.014623 Train acc: 0.997500\n",
      "Epoch: 359/1000 Iteration: 1080 Train loss: 0.008043 Train acc: 1.000000\n",
      "Epoch: 359/1000 Iteration: 1080 Validation loss: 0.038189 Validation acc: 0.988750\n",
      "Epoch: 361/1000 Iteration: 1085 Train loss: 0.010263 Train acc: 1.000000\n",
      "Epoch: 363/1000 Iteration: 1090 Train loss: 0.011109 Train acc: 0.997500\n",
      "Epoch: 363/1000 Iteration: 1090 Validation loss: 0.036034 Validation acc: 0.991250\n",
      "Epoch: 364/1000 Iteration: 1095 Train loss: 0.008229 Train acc: 1.000000\n",
      "Epoch: 366/1000 Iteration: 1100 Train loss: 0.007926 Train acc: 1.000000\n",
      "Epoch: 366/1000 Iteration: 1100 Validation loss: 0.037451 Validation acc: 0.988750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 368/1000 Iteration: 1105 Train loss: 0.010490 Train acc: 1.000000\n",
      "Epoch: 369/1000 Iteration: 1110 Train loss: 0.009767 Train acc: 1.000000\n",
      "Epoch: 369/1000 Iteration: 1110 Validation loss: 0.036473 Validation acc: 0.990000\n",
      "Epoch: 371/1000 Iteration: 1115 Train loss: 0.009993 Train acc: 1.000000\n",
      "Epoch: 373/1000 Iteration: 1120 Train loss: 0.010193 Train acc: 1.000000\n",
      "Epoch: 373/1000 Iteration: 1120 Validation loss: 0.036104 Validation acc: 0.990000\n",
      "Epoch: 374/1000 Iteration: 1125 Train loss: 0.006651 Train acc: 1.000000\n",
      "Epoch: 376/1000 Iteration: 1130 Train loss: 0.012309 Train acc: 1.000000\n",
      "Epoch: 376/1000 Iteration: 1130 Validation loss: 0.035741 Validation acc: 0.990000\n",
      "Epoch: 378/1000 Iteration: 1135 Train loss: 0.014050 Train acc: 0.997500\n",
      "Epoch: 379/1000 Iteration: 1140 Train loss: 0.012390 Train acc: 0.997500\n",
      "Epoch: 379/1000 Iteration: 1140 Validation loss: 0.036394 Validation acc: 0.988750\n",
      "Epoch: 381/1000 Iteration: 1145 Train loss: 0.008230 Train acc: 1.000000\n",
      "Epoch: 383/1000 Iteration: 1150 Train loss: 0.010354 Train acc: 1.000000\n",
      "Epoch: 383/1000 Iteration: 1150 Validation loss: 0.036446 Validation acc: 0.990000\n",
      "Epoch: 384/1000 Iteration: 1155 Train loss: 0.005416 Train acc: 1.000000\n",
      "Epoch: 386/1000 Iteration: 1160 Train loss: 0.009111 Train acc: 1.000000\n",
      "Epoch: 386/1000 Iteration: 1160 Validation loss: 0.036720 Validation acc: 0.988750\n",
      "Epoch: 388/1000 Iteration: 1165 Train loss: 0.011070 Train acc: 1.000000\n",
      "Epoch: 389/1000 Iteration: 1170 Train loss: 0.016674 Train acc: 0.995000\n",
      "Epoch: 389/1000 Iteration: 1170 Validation loss: 0.040062 Validation acc: 0.988750\n",
      "Epoch: 391/1000 Iteration: 1175 Train loss: 0.009499 Train acc: 1.000000\n",
      "Epoch: 393/1000 Iteration: 1180 Train loss: 0.010454 Train acc: 1.000000\n",
      "Epoch: 393/1000 Iteration: 1180 Validation loss: 0.035644 Validation acc: 0.990000\n",
      "Epoch: 394/1000 Iteration: 1185 Train loss: 0.006930 Train acc: 1.000000\n",
      "Epoch: 396/1000 Iteration: 1190 Train loss: 0.010295 Train acc: 0.997500\n",
      "Epoch: 396/1000 Iteration: 1190 Validation loss: 0.033719 Validation acc: 0.991250\n",
      "Epoch: 398/1000 Iteration: 1195 Train loss: 0.021291 Train acc: 0.992500\n",
      "Epoch: 399/1000 Iteration: 1200 Train loss: 0.011842 Train acc: 0.995000\n",
      "Epoch: 399/1000 Iteration: 1200 Validation loss: 0.037674 Validation acc: 0.988750\n",
      "Epoch: 401/1000 Iteration: 1205 Train loss: 0.007571 Train acc: 1.000000\n",
      "Epoch: 403/1000 Iteration: 1210 Train loss: 0.006445 Train acc: 1.000000\n",
      "Epoch: 403/1000 Iteration: 1210 Validation loss: 0.036175 Validation acc: 0.990000\n",
      "Epoch: 404/1000 Iteration: 1215 Train loss: 0.006582 Train acc: 1.000000\n",
      "Epoch: 406/1000 Iteration: 1220 Train loss: 0.010029 Train acc: 0.997500\n",
      "Epoch: 406/1000 Iteration: 1220 Validation loss: 0.035018 Validation acc: 0.990000\n",
      "Epoch: 408/1000 Iteration: 1225 Train loss: 0.018595 Train acc: 0.997500\n",
      "Epoch: 409/1000 Iteration: 1230 Train loss: 0.006267 Train acc: 1.000000\n",
      "Epoch: 409/1000 Iteration: 1230 Validation loss: 0.034812 Validation acc: 0.991250\n",
      "Epoch: 411/1000 Iteration: 1235 Train loss: 0.008944 Train acc: 1.000000\n",
      "Epoch: 413/1000 Iteration: 1240 Train loss: 0.012290 Train acc: 0.997500\n",
      "Epoch: 413/1000 Iteration: 1240 Validation loss: 0.034460 Validation acc: 0.991250\n",
      "Epoch: 414/1000 Iteration: 1245 Train loss: 0.005797 Train acc: 1.000000\n",
      "Epoch: 416/1000 Iteration: 1250 Train loss: 0.007878 Train acc: 1.000000\n",
      "Epoch: 416/1000 Iteration: 1250 Validation loss: 0.034677 Validation acc: 0.991250\n",
      "Epoch: 418/1000 Iteration: 1255 Train loss: 0.007396 Train acc: 1.000000\n",
      "Epoch: 419/1000 Iteration: 1260 Train loss: 0.007747 Train acc: 1.000000\n",
      "Epoch: 419/1000 Iteration: 1260 Validation loss: 0.034898 Validation acc: 0.991250\n",
      "Epoch: 421/1000 Iteration: 1265 Train loss: 0.007356 Train acc: 1.000000\n",
      "Epoch: 423/1000 Iteration: 1270 Train loss: 0.011221 Train acc: 0.997500\n",
      "Epoch: 423/1000 Iteration: 1270 Validation loss: 0.036060 Validation acc: 0.988750\n",
      "Epoch: 424/1000 Iteration: 1275 Train loss: 0.005551 Train acc: 1.000000\n",
      "Epoch: 426/1000 Iteration: 1280 Train loss: 0.007090 Train acc: 1.000000\n",
      "Epoch: 426/1000 Iteration: 1280 Validation loss: 0.033358 Validation acc: 0.991250\n",
      "Epoch: 428/1000 Iteration: 1285 Train loss: 0.010870 Train acc: 1.000000\n",
      "Epoch: 429/1000 Iteration: 1290 Train loss: 0.004210 Train acc: 1.000000\n",
      "Epoch: 429/1000 Iteration: 1290 Validation loss: 0.033278 Validation acc: 0.991250\n",
      "Epoch: 431/1000 Iteration: 1295 Train loss: 0.006997 Train acc: 1.000000\n",
      "Epoch: 433/1000 Iteration: 1300 Train loss: 0.006925 Train acc: 1.000000\n",
      "Epoch: 433/1000 Iteration: 1300 Validation loss: 0.033904 Validation acc: 0.991250\n",
      "Epoch: 434/1000 Iteration: 1305 Train loss: 0.007574 Train acc: 1.000000\n",
      "Epoch: 436/1000 Iteration: 1310 Train loss: 0.009916 Train acc: 0.997500\n",
      "Epoch: 436/1000 Iteration: 1310 Validation loss: 0.032573 Validation acc: 0.992500\n",
      "Epoch: 438/1000 Iteration: 1315 Train loss: 0.006735 Train acc: 1.000000\n",
      "Epoch: 439/1000 Iteration: 1320 Train loss: 0.006051 Train acc: 1.000000\n",
      "Epoch: 439/1000 Iteration: 1320 Validation loss: 0.032462 Validation acc: 0.990000\n",
      "Epoch: 441/1000 Iteration: 1325 Train loss: 0.005688 Train acc: 1.000000\n",
      "Epoch: 443/1000 Iteration: 1330 Train loss: 0.006935 Train acc: 1.000000\n",
      "Epoch: 443/1000 Iteration: 1330 Validation loss: 0.033540 Validation acc: 0.991250\n",
      "Epoch: 444/1000 Iteration: 1335 Train loss: 0.004470 Train acc: 1.000000\n",
      "Epoch: 446/1000 Iteration: 1340 Train loss: 0.009550 Train acc: 0.997500\n",
      "Epoch: 446/1000 Iteration: 1340 Validation loss: 0.033811 Validation acc: 0.991250\n",
      "Epoch: 448/1000 Iteration: 1345 Train loss: 0.007798 Train acc: 0.997500\n",
      "Epoch: 449/1000 Iteration: 1350 Train loss: 0.004583 Train acc: 1.000000\n",
      "Epoch: 449/1000 Iteration: 1350 Validation loss: 0.031733 Validation acc: 0.992500\n",
      "Epoch: 451/1000 Iteration: 1355 Train loss: 0.008153 Train acc: 0.997500\n",
      "Epoch: 453/1000 Iteration: 1360 Train loss: 0.006833 Train acc: 1.000000\n",
      "Epoch: 453/1000 Iteration: 1360 Validation loss: 0.033623 Validation acc: 0.991250\n",
      "Epoch: 454/1000 Iteration: 1365 Train loss: 0.005671 Train acc: 1.000000\n",
      "Epoch: 456/1000 Iteration: 1370 Train loss: 0.007046 Train acc: 1.000000\n",
      "Epoch: 456/1000 Iteration: 1370 Validation loss: 0.033192 Validation acc: 0.990000\n",
      "Epoch: 458/1000 Iteration: 1375 Train loss: 0.007556 Train acc: 1.000000\n",
      "Epoch: 459/1000 Iteration: 1380 Train loss: 0.005805 Train acc: 1.000000\n",
      "Epoch: 459/1000 Iteration: 1380 Validation loss: 0.034014 Validation acc: 0.991250\n",
      "Epoch: 461/1000 Iteration: 1385 Train loss: 0.007624 Train acc: 1.000000\n",
      "Epoch: 463/1000 Iteration: 1390 Train loss: 0.006450 Train acc: 1.000000\n",
      "Epoch: 463/1000 Iteration: 1390 Validation loss: 0.032718 Validation acc: 0.992500\n",
      "Epoch: 464/1000 Iteration: 1395 Train loss: 0.007479 Train acc: 0.997500\n",
      "Epoch: 466/1000 Iteration: 1400 Train loss: 0.005919 Train acc: 1.000000\n",
      "Epoch: 466/1000 Iteration: 1400 Validation loss: 0.032055 Validation acc: 0.992500\n",
      "Epoch: 468/1000 Iteration: 1405 Train loss: 0.006670 Train acc: 1.000000\n",
      "Epoch: 469/1000 Iteration: 1410 Train loss: 0.004269 Train acc: 1.000000\n",
      "Epoch: 469/1000 Iteration: 1410 Validation loss: 0.032846 Validation acc: 0.991250\n",
      "Epoch: 471/1000 Iteration: 1415 Train loss: 0.004914 Train acc: 1.000000\n",
      "Epoch: 473/1000 Iteration: 1420 Train loss: 0.005116 Train acc: 1.000000\n",
      "Epoch: 473/1000 Iteration: 1420 Validation loss: 0.032761 Validation acc: 0.991250\n",
      "Epoch: 474/1000 Iteration: 1425 Train loss: 0.005696 Train acc: 1.000000\n",
      "Epoch: 476/1000 Iteration: 1430 Train loss: 0.007348 Train acc: 0.997500\n",
      "Epoch: 476/1000 Iteration: 1430 Validation loss: 0.033366 Validation acc: 0.990000\n",
      "Epoch: 478/1000 Iteration: 1435 Train loss: 0.005185 Train acc: 1.000000\n",
      "Epoch: 479/1000 Iteration: 1440 Train loss: 0.007083 Train acc: 0.997500\n",
      "Epoch: 479/1000 Iteration: 1440 Validation loss: 0.029976 Validation acc: 0.992500\n",
      "Epoch: 481/1000 Iteration: 1445 Train loss: 0.004926 Train acc: 1.000000\n",
      "Epoch: 483/1000 Iteration: 1450 Train loss: 0.007829 Train acc: 0.997500\n",
      "Epoch: 483/1000 Iteration: 1450 Validation loss: 0.029964 Validation acc: 0.992500\n",
      "Epoch: 484/1000 Iteration: 1455 Train loss: 0.006498 Train acc: 1.000000\n",
      "Epoch: 486/1000 Iteration: 1460 Train loss: 0.003775 Train acc: 1.000000\n",
      "Epoch: 486/1000 Iteration: 1460 Validation loss: 0.031753 Validation acc: 0.991250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 488/1000 Iteration: 1465 Train loss: 0.004962 Train acc: 1.000000\n",
      "Epoch: 489/1000 Iteration: 1470 Train loss: 0.004372 Train acc: 1.000000\n",
      "Epoch: 489/1000 Iteration: 1470 Validation loss: 0.031037 Validation acc: 0.992500\n",
      "Epoch: 491/1000 Iteration: 1475 Train loss: 0.003570 Train acc: 1.000000\n",
      "Epoch: 493/1000 Iteration: 1480 Train loss: 0.004401 Train acc: 1.000000\n",
      "Epoch: 493/1000 Iteration: 1480 Validation loss: 0.031225 Validation acc: 0.991250\n",
      "Epoch: 494/1000 Iteration: 1485 Train loss: 0.003763 Train acc: 1.000000\n",
      "Epoch: 496/1000 Iteration: 1490 Train loss: 0.005135 Train acc: 1.000000\n",
      "Epoch: 496/1000 Iteration: 1490 Validation loss: 0.031231 Validation acc: 0.991250\n",
      "Epoch: 498/1000 Iteration: 1495 Train loss: 0.004338 Train acc: 1.000000\n",
      "Epoch: 499/1000 Iteration: 1500 Train loss: 0.007908 Train acc: 1.000000\n",
      "Epoch: 499/1000 Iteration: 1500 Validation loss: 0.030883 Validation acc: 0.992500\n",
      "Epoch: 501/1000 Iteration: 1505 Train loss: 0.004738 Train acc: 1.000000\n",
      "Epoch: 503/1000 Iteration: 1510 Train loss: 0.005564 Train acc: 1.000000\n",
      "Epoch: 503/1000 Iteration: 1510 Validation loss: 0.029959 Validation acc: 0.991250\n",
      "Epoch: 504/1000 Iteration: 1515 Train loss: 0.004449 Train acc: 1.000000\n",
      "Epoch: 506/1000 Iteration: 1520 Train loss: 0.004787 Train acc: 1.000000\n",
      "Epoch: 506/1000 Iteration: 1520 Validation loss: 0.030532 Validation acc: 0.991250\n",
      "Epoch: 508/1000 Iteration: 1525 Train loss: 0.005289 Train acc: 1.000000\n",
      "Epoch: 509/1000 Iteration: 1530 Train loss: 0.006215 Train acc: 1.000000\n",
      "Epoch: 509/1000 Iteration: 1530 Validation loss: 0.031547 Validation acc: 0.991250\n",
      "Epoch: 511/1000 Iteration: 1535 Train loss: 0.004870 Train acc: 1.000000\n",
      "Epoch: 513/1000 Iteration: 1540 Train loss: 0.006658 Train acc: 1.000000\n",
      "Epoch: 513/1000 Iteration: 1540 Validation loss: 0.030247 Validation acc: 0.992500\n",
      "Epoch: 514/1000 Iteration: 1545 Train loss: 0.004087 Train acc: 1.000000\n",
      "Epoch: 516/1000 Iteration: 1550 Train loss: 0.004529 Train acc: 1.000000\n",
      "Epoch: 516/1000 Iteration: 1550 Validation loss: 0.029764 Validation acc: 0.991250\n",
      "Epoch: 518/1000 Iteration: 1555 Train loss: 0.006792 Train acc: 1.000000\n",
      "Epoch: 519/1000 Iteration: 1560 Train loss: 0.003650 Train acc: 1.000000\n",
      "Epoch: 519/1000 Iteration: 1560 Validation loss: 0.031166 Validation acc: 0.991250\n",
      "Epoch: 521/1000 Iteration: 1565 Train loss: 0.005729 Train acc: 0.997500\n",
      "Epoch: 523/1000 Iteration: 1570 Train loss: 0.004882 Train acc: 1.000000\n",
      "Epoch: 523/1000 Iteration: 1570 Validation loss: 0.030704 Validation acc: 0.991250\n",
      "Epoch: 524/1000 Iteration: 1575 Train loss: 0.005394 Train acc: 1.000000\n",
      "Epoch: 526/1000 Iteration: 1580 Train loss: 0.003542 Train acc: 1.000000\n",
      "Epoch: 526/1000 Iteration: 1580 Validation loss: 0.030861 Validation acc: 0.992500\n",
      "Epoch: 528/1000 Iteration: 1585 Train loss: 0.003749 Train acc: 1.000000\n",
      "Epoch: 529/1000 Iteration: 1590 Train loss: 0.003202 Train acc: 1.000000\n",
      "Epoch: 529/1000 Iteration: 1590 Validation loss: 0.031118 Validation acc: 0.992500\n",
      "Epoch: 531/1000 Iteration: 1595 Train loss: 0.003644 Train acc: 1.000000\n",
      "Epoch: 533/1000 Iteration: 1600 Train loss: 0.005363 Train acc: 1.000000\n",
      "Epoch: 533/1000 Iteration: 1600 Validation loss: 0.030080 Validation acc: 0.991250\n",
      "Epoch: 534/1000 Iteration: 1605 Train loss: 0.008564 Train acc: 0.997500\n",
      "Epoch: 536/1000 Iteration: 1610 Train loss: 0.004061 Train acc: 1.000000\n",
      "Epoch: 536/1000 Iteration: 1610 Validation loss: 0.029981 Validation acc: 0.992500\n",
      "Epoch: 538/1000 Iteration: 1615 Train loss: 0.010361 Train acc: 0.997500\n",
      "Epoch: 539/1000 Iteration: 1620 Train loss: 0.003205 Train acc: 1.000000\n",
      "Epoch: 539/1000 Iteration: 1620 Validation loss: 0.029671 Validation acc: 0.993750\n",
      "Epoch: 541/1000 Iteration: 1625 Train loss: 0.004552 Train acc: 1.000000\n",
      "Epoch: 543/1000 Iteration: 1630 Train loss: 0.003755 Train acc: 1.000000\n",
      "Epoch: 543/1000 Iteration: 1630 Validation loss: 0.028844 Validation acc: 0.993750\n",
      "Epoch: 544/1000 Iteration: 1635 Train loss: 0.003118 Train acc: 1.000000\n",
      "Epoch: 546/1000 Iteration: 1640 Train loss: 0.003481 Train acc: 1.000000\n",
      "Epoch: 546/1000 Iteration: 1640 Validation loss: 0.029200 Validation acc: 0.992500\n",
      "Epoch: 548/1000 Iteration: 1645 Train loss: 0.004767 Train acc: 1.000000\n",
      "Epoch: 549/1000 Iteration: 1650 Train loss: 0.003284 Train acc: 1.000000\n",
      "Epoch: 549/1000 Iteration: 1650 Validation loss: 0.029284 Validation acc: 0.991250\n",
      "Epoch: 551/1000 Iteration: 1655 Train loss: 0.003769 Train acc: 1.000000\n",
      "Epoch: 553/1000 Iteration: 1660 Train loss: 0.002896 Train acc: 1.000000\n",
      "Epoch: 553/1000 Iteration: 1660 Validation loss: 0.029864 Validation acc: 0.990000\n",
      "Epoch: 554/1000 Iteration: 1665 Train loss: 0.002624 Train acc: 1.000000\n",
      "Epoch: 556/1000 Iteration: 1670 Train loss: 0.004450 Train acc: 1.000000\n",
      "Epoch: 556/1000 Iteration: 1670 Validation loss: 0.030875 Validation acc: 0.991250\n",
      "Epoch: 558/1000 Iteration: 1675 Train loss: 0.004623 Train acc: 1.000000\n",
      "Epoch: 559/1000 Iteration: 1680 Train loss: 0.004086 Train acc: 1.000000\n",
      "Epoch: 559/1000 Iteration: 1680 Validation loss: 0.030268 Validation acc: 0.991250\n",
      "Epoch: 561/1000 Iteration: 1685 Train loss: 0.003139 Train acc: 1.000000\n",
      "Epoch: 563/1000 Iteration: 1690 Train loss: 0.004987 Train acc: 1.000000\n",
      "Epoch: 563/1000 Iteration: 1690 Validation loss: 0.029144 Validation acc: 0.992500\n",
      "Epoch: 564/1000 Iteration: 1695 Train loss: 0.002556 Train acc: 1.000000\n",
      "Epoch: 566/1000 Iteration: 1700 Train loss: 0.002956 Train acc: 1.000000\n",
      "Epoch: 566/1000 Iteration: 1700 Validation loss: 0.030177 Validation acc: 0.992500\n",
      "Epoch: 568/1000 Iteration: 1705 Train loss: 0.003908 Train acc: 1.000000\n",
      "Epoch: 569/1000 Iteration: 1710 Train loss: 0.004287 Train acc: 1.000000\n",
      "Epoch: 569/1000 Iteration: 1710 Validation loss: 0.028971 Validation acc: 0.992500\n",
      "Epoch: 571/1000 Iteration: 1715 Train loss: 0.004047 Train acc: 1.000000\n",
      "Epoch: 573/1000 Iteration: 1720 Train loss: 0.003072 Train acc: 1.000000\n",
      "Epoch: 573/1000 Iteration: 1720 Validation loss: 0.029668 Validation acc: 0.991250\n",
      "Epoch: 574/1000 Iteration: 1725 Train loss: 0.002774 Train acc: 1.000000\n",
      "Epoch: 576/1000 Iteration: 1730 Train loss: 0.006552 Train acc: 0.997500\n",
      "Epoch: 576/1000 Iteration: 1730 Validation loss: 0.029670 Validation acc: 0.992500\n",
      "Epoch: 578/1000 Iteration: 1735 Train loss: 0.005037 Train acc: 1.000000\n",
      "Epoch: 579/1000 Iteration: 1740 Train loss: 0.002386 Train acc: 1.000000\n",
      "Epoch: 579/1000 Iteration: 1740 Validation loss: 0.028875 Validation acc: 0.992500\n",
      "Epoch: 581/1000 Iteration: 1745 Train loss: 0.002803 Train acc: 1.000000\n",
      "Epoch: 583/1000 Iteration: 1750 Train loss: 0.009350 Train acc: 0.995000\n",
      "Epoch: 583/1000 Iteration: 1750 Validation loss: 0.028926 Validation acc: 0.991250\n",
      "Epoch: 584/1000 Iteration: 1755 Train loss: 0.005938 Train acc: 1.000000\n",
      "Epoch: 586/1000 Iteration: 1760 Train loss: 0.003757 Train acc: 1.000000\n",
      "Epoch: 586/1000 Iteration: 1760 Validation loss: 0.029440 Validation acc: 0.990000\n",
      "Epoch: 588/1000 Iteration: 1765 Train loss: 0.003703 Train acc: 1.000000\n",
      "Epoch: 589/1000 Iteration: 1770 Train loss: 0.002158 Train acc: 1.000000\n",
      "Epoch: 589/1000 Iteration: 1770 Validation loss: 0.030418 Validation acc: 0.991250\n",
      "Epoch: 591/1000 Iteration: 1775 Train loss: 0.002517 Train acc: 1.000000\n",
      "Epoch: 593/1000 Iteration: 1780 Train loss: 0.004369 Train acc: 1.000000\n",
      "Epoch: 593/1000 Iteration: 1780 Validation loss: 0.028516 Validation acc: 0.992500\n",
      "Epoch: 594/1000 Iteration: 1785 Train loss: 0.002752 Train acc: 1.000000\n",
      "Epoch: 596/1000 Iteration: 1790 Train loss: 0.003931 Train acc: 1.000000\n",
      "Epoch: 596/1000 Iteration: 1790 Validation loss: 0.027709 Validation acc: 0.993750\n",
      "Epoch: 598/1000 Iteration: 1795 Train loss: 0.004406 Train acc: 1.000000\n",
      "Epoch: 599/1000 Iteration: 1800 Train loss: 0.001889 Train acc: 1.000000\n",
      "Epoch: 599/1000 Iteration: 1800 Validation loss: 0.030446 Validation acc: 0.992500\n",
      "Epoch: 601/1000 Iteration: 1805 Train loss: 0.002826 Train acc: 1.000000\n",
      "Epoch: 603/1000 Iteration: 1810 Train loss: 0.004209 Train acc: 1.000000\n",
      "Epoch: 603/1000 Iteration: 1810 Validation loss: 0.030163 Validation acc: 0.991250\n",
      "Epoch: 604/1000 Iteration: 1815 Train loss: 0.001925 Train acc: 1.000000\n",
      "Epoch: 606/1000 Iteration: 1820 Train loss: 0.002931 Train acc: 1.000000\n",
      "Epoch: 606/1000 Iteration: 1820 Validation loss: 0.029205 Validation acc: 0.990000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 608/1000 Iteration: 1825 Train loss: 0.002459 Train acc: 1.000000\n",
      "Epoch: 609/1000 Iteration: 1830 Train loss: 0.003052 Train acc: 1.000000\n",
      "Epoch: 609/1000 Iteration: 1830 Validation loss: 0.029854 Validation acc: 0.991250\n",
      "Epoch: 611/1000 Iteration: 1835 Train loss: 0.003677 Train acc: 1.000000\n",
      "Epoch: 613/1000 Iteration: 1840 Train loss: 0.005447 Train acc: 0.997500\n",
      "Epoch: 613/1000 Iteration: 1840 Validation loss: 0.030444 Validation acc: 0.991250\n",
      "Epoch: 614/1000 Iteration: 1845 Train loss: 0.002306 Train acc: 1.000000\n",
      "Epoch: 616/1000 Iteration: 1850 Train loss: 0.002546 Train acc: 1.000000\n",
      "Epoch: 616/1000 Iteration: 1850 Validation loss: 0.029318 Validation acc: 0.991250\n",
      "Epoch: 618/1000 Iteration: 1855 Train loss: 0.003655 Train acc: 1.000000\n",
      "Epoch: 619/1000 Iteration: 1860 Train loss: 0.002453 Train acc: 1.000000\n",
      "Epoch: 619/1000 Iteration: 1860 Validation loss: 0.028839 Validation acc: 0.992500\n",
      "Epoch: 621/1000 Iteration: 1865 Train loss: 0.002814 Train acc: 1.000000\n",
      "Epoch: 623/1000 Iteration: 1870 Train loss: 0.002475 Train acc: 1.000000\n",
      "Epoch: 623/1000 Iteration: 1870 Validation loss: 0.029284 Validation acc: 0.992500\n",
      "Epoch: 624/1000 Iteration: 1875 Train loss: 0.002740 Train acc: 1.000000\n",
      "Epoch: 626/1000 Iteration: 1880 Train loss: 0.002924 Train acc: 1.000000\n",
      "Epoch: 626/1000 Iteration: 1880 Validation loss: 0.028602 Validation acc: 0.992500\n",
      "Epoch: 628/1000 Iteration: 1885 Train loss: 0.005660 Train acc: 1.000000\n",
      "Epoch: 629/1000 Iteration: 1890 Train loss: 0.002352 Train acc: 1.000000\n",
      "Epoch: 629/1000 Iteration: 1890 Validation loss: 0.027978 Validation acc: 0.991250\n",
      "Epoch: 631/1000 Iteration: 1895 Train loss: 0.003749 Train acc: 1.000000\n",
      "Epoch: 633/1000 Iteration: 1900 Train loss: 0.003404 Train acc: 1.000000\n",
      "Epoch: 633/1000 Iteration: 1900 Validation loss: 0.027582 Validation acc: 0.991250\n",
      "Epoch: 634/1000 Iteration: 1905 Train loss: 0.002370 Train acc: 1.000000\n",
      "Epoch: 636/1000 Iteration: 1910 Train loss: 0.002300 Train acc: 1.000000\n",
      "Epoch: 636/1000 Iteration: 1910 Validation loss: 0.028216 Validation acc: 0.992500\n",
      "Epoch: 638/1000 Iteration: 1915 Train loss: 0.006226 Train acc: 0.997500\n",
      "Epoch: 639/1000 Iteration: 1920 Train loss: 0.004022 Train acc: 1.000000\n",
      "Epoch: 639/1000 Iteration: 1920 Validation loss: 0.028417 Validation acc: 0.992500\n",
      "Epoch: 641/1000 Iteration: 1925 Train loss: 0.003387 Train acc: 1.000000\n",
      "Epoch: 643/1000 Iteration: 1930 Train loss: 0.002903 Train acc: 1.000000\n",
      "Epoch: 643/1000 Iteration: 1930 Validation loss: 0.027895 Validation acc: 0.991250\n",
      "Epoch: 644/1000 Iteration: 1935 Train loss: 0.002463 Train acc: 1.000000\n",
      "Epoch: 646/1000 Iteration: 1940 Train loss: 0.002615 Train acc: 1.000000\n",
      "Epoch: 646/1000 Iteration: 1940 Validation loss: 0.027812 Validation acc: 0.991250\n",
      "Epoch: 648/1000 Iteration: 1945 Train loss: 0.002678 Train acc: 1.000000\n",
      "Epoch: 649/1000 Iteration: 1950 Train loss: 0.002197 Train acc: 1.000000\n",
      "Epoch: 649/1000 Iteration: 1950 Validation loss: 0.028355 Validation acc: 0.992500\n",
      "Epoch: 651/1000 Iteration: 1955 Train loss: 0.002163 Train acc: 1.000000\n",
      "Epoch: 653/1000 Iteration: 1960 Train loss: 0.002697 Train acc: 1.000000\n",
      "Epoch: 653/1000 Iteration: 1960 Validation loss: 0.028367 Validation acc: 0.992500\n",
      "Epoch: 654/1000 Iteration: 1965 Train loss: 0.005482 Train acc: 0.997500\n",
      "Epoch: 656/1000 Iteration: 1970 Train loss: 0.005231 Train acc: 1.000000\n",
      "Epoch: 656/1000 Iteration: 1970 Validation loss: 0.028698 Validation acc: 0.992500\n",
      "Epoch: 658/1000 Iteration: 1975 Train loss: 0.002875 Train acc: 1.000000\n",
      "Epoch: 659/1000 Iteration: 1980 Train loss: 0.001979 Train acc: 1.000000\n",
      "Epoch: 659/1000 Iteration: 1980 Validation loss: 0.028432 Validation acc: 0.992500\n",
      "Epoch: 661/1000 Iteration: 1985 Train loss: 0.001938 Train acc: 1.000000\n",
      "Epoch: 663/1000 Iteration: 1990 Train loss: 0.004273 Train acc: 1.000000\n",
      "Epoch: 663/1000 Iteration: 1990 Validation loss: 0.029116 Validation acc: 0.992500\n",
      "Epoch: 664/1000 Iteration: 1995 Train loss: 0.001823 Train acc: 1.000000\n",
      "Epoch: 666/1000 Iteration: 2000 Train loss: 0.002326 Train acc: 1.000000\n",
      "Epoch: 666/1000 Iteration: 2000 Validation loss: 0.029596 Validation acc: 0.991250\n",
      "Epoch: 668/1000 Iteration: 2005 Train loss: 0.002708 Train acc: 1.000000\n",
      "Epoch: 669/1000 Iteration: 2010 Train loss: 0.004683 Train acc: 1.000000\n",
      "Epoch: 669/1000 Iteration: 2010 Validation loss: 0.028967 Validation acc: 0.991250\n",
      "Epoch: 671/1000 Iteration: 2015 Train loss: 0.002656 Train acc: 1.000000\n",
      "Epoch: 673/1000 Iteration: 2020 Train loss: 0.001786 Train acc: 1.000000\n",
      "Epoch: 673/1000 Iteration: 2020 Validation loss: 0.027392 Validation acc: 0.992500\n",
      "Epoch: 674/1000 Iteration: 2025 Train loss: 0.003295 Train acc: 1.000000\n",
      "Epoch: 676/1000 Iteration: 2030 Train loss: 0.002638 Train acc: 1.000000\n",
      "Epoch: 676/1000 Iteration: 2030 Validation loss: 0.026875 Validation acc: 0.993750\n",
      "Epoch: 678/1000 Iteration: 2035 Train loss: 0.002794 Train acc: 1.000000\n",
      "Epoch: 679/1000 Iteration: 2040 Train loss: 0.003173 Train acc: 1.000000\n",
      "Epoch: 679/1000 Iteration: 2040 Validation loss: 0.028446 Validation acc: 0.992500\n",
      "Epoch: 681/1000 Iteration: 2045 Train loss: 0.003256 Train acc: 1.000000\n",
      "Epoch: 683/1000 Iteration: 2050 Train loss: 0.003204 Train acc: 1.000000\n",
      "Epoch: 683/1000 Iteration: 2050 Validation loss: 0.028157 Validation acc: 0.992500\n",
      "Epoch: 684/1000 Iteration: 2055 Train loss: 0.001971 Train acc: 1.000000\n",
      "Epoch: 686/1000 Iteration: 2060 Train loss: 0.002668 Train acc: 1.000000\n",
      "Epoch: 686/1000 Iteration: 2060 Validation loss: 0.028756 Validation acc: 0.992500\n",
      "Epoch: 688/1000 Iteration: 2065 Train loss: 0.003285 Train acc: 1.000000\n",
      "Epoch: 689/1000 Iteration: 2070 Train loss: 0.001513 Train acc: 1.000000\n",
      "Epoch: 689/1000 Iteration: 2070 Validation loss: 0.027547 Validation acc: 0.991250\n",
      "Epoch: 691/1000 Iteration: 2075 Train loss: 0.002149 Train acc: 1.000000\n",
      "Epoch: 693/1000 Iteration: 2080 Train loss: 0.001557 Train acc: 1.000000\n",
      "Epoch: 693/1000 Iteration: 2080 Validation loss: 0.027363 Validation acc: 0.991250\n",
      "Epoch: 694/1000 Iteration: 2085 Train loss: 0.001900 Train acc: 1.000000\n",
      "Epoch: 696/1000 Iteration: 2090 Train loss: 0.003361 Train acc: 1.000000\n",
      "Epoch: 696/1000 Iteration: 2090 Validation loss: 0.028049 Validation acc: 0.992500\n",
      "Epoch: 698/1000 Iteration: 2095 Train loss: 0.003172 Train acc: 1.000000\n",
      "Epoch: 699/1000 Iteration: 2100 Train loss: 0.001608 Train acc: 1.000000\n",
      "Epoch: 699/1000 Iteration: 2100 Validation loss: 0.029609 Validation acc: 0.992500\n",
      "Epoch: 701/1000 Iteration: 2105 Train loss: 0.002093 Train acc: 1.000000\n",
      "Epoch: 703/1000 Iteration: 2110 Train loss: 0.003574 Train acc: 1.000000\n",
      "Epoch: 703/1000 Iteration: 2110 Validation loss: 0.028201 Validation acc: 0.992500\n",
      "Epoch: 704/1000 Iteration: 2115 Train loss: 0.001987 Train acc: 1.000000\n",
      "Epoch: 706/1000 Iteration: 2120 Train loss: 0.002105 Train acc: 1.000000\n",
      "Epoch: 706/1000 Iteration: 2120 Validation loss: 0.027323 Validation acc: 0.992500\n",
      "Epoch: 708/1000 Iteration: 2125 Train loss: 0.002099 Train acc: 1.000000\n",
      "Epoch: 709/1000 Iteration: 2130 Train loss: 0.001676 Train acc: 1.000000\n",
      "Epoch: 709/1000 Iteration: 2130 Validation loss: 0.026464 Validation acc: 0.993750\n",
      "Epoch: 711/1000 Iteration: 2135 Train loss: 0.001502 Train acc: 1.000000\n",
      "Epoch: 713/1000 Iteration: 2140 Train loss: 0.001766 Train acc: 1.000000\n",
      "Epoch: 713/1000 Iteration: 2140 Validation loss: 0.026563 Validation acc: 0.993750\n",
      "Epoch: 714/1000 Iteration: 2145 Train loss: 0.002417 Train acc: 1.000000\n",
      "Epoch: 716/1000 Iteration: 2150 Train loss: 0.002681 Train acc: 1.000000\n",
      "Epoch: 716/1000 Iteration: 2150 Validation loss: 0.027044 Validation acc: 0.992500\n",
      "Epoch: 718/1000 Iteration: 2155 Train loss: 0.005920 Train acc: 0.997500\n",
      "Epoch: 719/1000 Iteration: 2160 Train loss: 0.001696 Train acc: 1.000000\n",
      "Epoch: 719/1000 Iteration: 2160 Validation loss: 0.026951 Validation acc: 0.992500\n",
      "Epoch: 721/1000 Iteration: 2165 Train loss: 0.001611 Train acc: 1.000000\n",
      "Epoch: 723/1000 Iteration: 2170 Train loss: 0.001834 Train acc: 1.000000\n",
      "Epoch: 723/1000 Iteration: 2170 Validation loss: 0.027277 Validation acc: 0.991250\n",
      "Epoch: 724/1000 Iteration: 2175 Train loss: 0.002422 Train acc: 1.000000\n",
      "Epoch: 726/1000 Iteration: 2180 Train loss: 0.001381 Train acc: 1.000000\n",
      "Epoch: 726/1000 Iteration: 2180 Validation loss: 0.027801 Validation acc: 0.991250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 728/1000 Iteration: 2185 Train loss: 0.002728 Train acc: 1.000000\n",
      "Epoch: 729/1000 Iteration: 2190 Train loss: 0.001973 Train acc: 1.000000\n",
      "Epoch: 729/1000 Iteration: 2190 Validation loss: 0.027149 Validation acc: 0.991250\n",
      "Epoch: 731/1000 Iteration: 2195 Train loss: 0.001687 Train acc: 1.000000\n",
      "Epoch: 733/1000 Iteration: 2200 Train loss: 0.002447 Train acc: 1.000000\n",
      "Epoch: 733/1000 Iteration: 2200 Validation loss: 0.029167 Validation acc: 0.992500\n",
      "Epoch: 734/1000 Iteration: 2205 Train loss: 0.001777 Train acc: 1.000000\n",
      "Epoch: 736/1000 Iteration: 2210 Train loss: 0.001377 Train acc: 1.000000\n",
      "Epoch: 736/1000 Iteration: 2210 Validation loss: 0.026777 Validation acc: 0.993750\n",
      "Epoch: 738/1000 Iteration: 2215 Train loss: 0.001687 Train acc: 1.000000\n",
      "Epoch: 739/1000 Iteration: 2220 Train loss: 0.002258 Train acc: 1.000000\n",
      "Epoch: 739/1000 Iteration: 2220 Validation loss: 0.026234 Validation acc: 0.992500\n",
      "Epoch: 741/1000 Iteration: 2225 Train loss: 0.001878 Train acc: 1.000000\n",
      "Epoch: 743/1000 Iteration: 2230 Train loss: 0.001989 Train acc: 1.000000\n",
      "Epoch: 743/1000 Iteration: 2230 Validation loss: 0.026434 Validation acc: 0.993750\n",
      "Epoch: 744/1000 Iteration: 2235 Train loss: 0.002817 Train acc: 1.000000\n",
      "Epoch: 746/1000 Iteration: 2240 Train loss: 0.002008 Train acc: 1.000000\n",
      "Epoch: 746/1000 Iteration: 2240 Validation loss: 0.025860 Validation acc: 0.993750\n",
      "Epoch: 748/1000 Iteration: 2245 Train loss: 0.002173 Train acc: 1.000000\n",
      "Epoch: 749/1000 Iteration: 2250 Train loss: 0.001026 Train acc: 1.000000\n",
      "Epoch: 749/1000 Iteration: 2250 Validation loss: 0.025407 Validation acc: 0.993750\n",
      "Epoch: 751/1000 Iteration: 2255 Train loss: 0.002231 Train acc: 1.000000\n",
      "Epoch: 753/1000 Iteration: 2260 Train loss: 0.005583 Train acc: 0.997500\n",
      "Epoch: 753/1000 Iteration: 2260 Validation loss: 0.026254 Validation acc: 0.993750\n",
      "Epoch: 754/1000 Iteration: 2265 Train loss: 0.002203 Train acc: 1.000000\n",
      "Epoch: 756/1000 Iteration: 2270 Train loss: 0.002405 Train acc: 1.000000\n",
      "Epoch: 756/1000 Iteration: 2270 Validation loss: 0.028705 Validation acc: 0.991250\n",
      "Epoch: 758/1000 Iteration: 2275 Train loss: 0.001685 Train acc: 1.000000\n",
      "Epoch: 759/1000 Iteration: 2280 Train loss: 0.001545 Train acc: 1.000000\n",
      "Epoch: 759/1000 Iteration: 2280 Validation loss: 0.028418 Validation acc: 0.991250\n",
      "Epoch: 761/1000 Iteration: 2285 Train loss: 0.003174 Train acc: 1.000000\n",
      "Epoch: 763/1000 Iteration: 2290 Train loss: 0.002737 Train acc: 1.000000\n",
      "Epoch: 763/1000 Iteration: 2290 Validation loss: 0.027249 Validation acc: 0.992500\n",
      "Epoch: 764/1000 Iteration: 2295 Train loss: 0.001444 Train acc: 1.000000\n",
      "Epoch: 766/1000 Iteration: 2300 Train loss: 0.001526 Train acc: 1.000000\n",
      "Epoch: 766/1000 Iteration: 2300 Validation loss: 0.026200 Validation acc: 0.995000\n",
      "Epoch: 768/1000 Iteration: 2305 Train loss: 0.001309 Train acc: 1.000000\n",
      "Epoch: 769/1000 Iteration: 2310 Train loss: 0.002176 Train acc: 1.000000\n",
      "Epoch: 769/1000 Iteration: 2310 Validation loss: 0.026824 Validation acc: 0.993750\n",
      "Epoch: 771/1000 Iteration: 2315 Train loss: 0.003747 Train acc: 0.997500\n",
      "Epoch: 773/1000 Iteration: 2320 Train loss: 0.001578 Train acc: 1.000000\n",
      "Epoch: 773/1000 Iteration: 2320 Validation loss: 0.027458 Validation acc: 0.991250\n",
      "Epoch: 774/1000 Iteration: 2325 Train loss: 0.001932 Train acc: 1.000000\n",
      "Epoch: 776/1000 Iteration: 2330 Train loss: 0.001255 Train acc: 1.000000\n",
      "Epoch: 776/1000 Iteration: 2330 Validation loss: 0.026841 Validation acc: 0.992500\n",
      "Epoch: 778/1000 Iteration: 2335 Train loss: 0.001872 Train acc: 1.000000\n",
      "Epoch: 779/1000 Iteration: 2340 Train loss: 0.001384 Train acc: 1.000000\n",
      "Epoch: 779/1000 Iteration: 2340 Validation loss: 0.026795 Validation acc: 0.993750\n",
      "Epoch: 781/1000 Iteration: 2345 Train loss: 0.001485 Train acc: 1.000000\n",
      "Epoch: 783/1000 Iteration: 2350 Train loss: 0.001505 Train acc: 1.000000\n",
      "Epoch: 783/1000 Iteration: 2350 Validation loss: 0.026678 Validation acc: 0.993750\n",
      "Epoch: 784/1000 Iteration: 2355 Train loss: 0.001434 Train acc: 1.000000\n",
      "Epoch: 786/1000 Iteration: 2360 Train loss: 0.001497 Train acc: 1.000000\n",
      "Epoch: 786/1000 Iteration: 2360 Validation loss: 0.026180 Validation acc: 0.993750\n",
      "Epoch: 788/1000 Iteration: 2365 Train loss: 0.001507 Train acc: 1.000000\n",
      "Epoch: 789/1000 Iteration: 2370 Train loss: 0.001909 Train acc: 1.000000\n",
      "Epoch: 789/1000 Iteration: 2370 Validation loss: 0.025806 Validation acc: 0.993750\n",
      "Epoch: 791/1000 Iteration: 2375 Train loss: 0.001610 Train acc: 1.000000\n",
      "Epoch: 793/1000 Iteration: 2380 Train loss: 0.001009 Train acc: 1.000000\n",
      "Epoch: 793/1000 Iteration: 2380 Validation loss: 0.025911 Validation acc: 0.993750\n",
      "Epoch: 794/1000 Iteration: 2385 Train loss: 0.001051 Train acc: 1.000000\n",
      "Epoch: 796/1000 Iteration: 2390 Train loss: 0.001474 Train acc: 1.000000\n",
      "Epoch: 796/1000 Iteration: 2390 Validation loss: 0.026571 Validation acc: 0.993750\n",
      "Epoch: 798/1000 Iteration: 2395 Train loss: 0.002071 Train acc: 1.000000\n",
      "Epoch: 799/1000 Iteration: 2400 Train loss: 0.003074 Train acc: 0.997500\n",
      "Epoch: 799/1000 Iteration: 2400 Validation loss: 0.026396 Validation acc: 0.993750\n",
      "Epoch: 801/1000 Iteration: 2405 Train loss: 0.000952 Train acc: 1.000000\n",
      "Epoch: 803/1000 Iteration: 2410 Train loss: 0.001896 Train acc: 1.000000\n",
      "Epoch: 803/1000 Iteration: 2410 Validation loss: 0.025369 Validation acc: 0.993750\n",
      "Epoch: 804/1000 Iteration: 2415 Train loss: 0.001114 Train acc: 1.000000\n",
      "Epoch: 806/1000 Iteration: 2420 Train loss: 0.001505 Train acc: 1.000000\n",
      "Epoch: 806/1000 Iteration: 2420 Validation loss: 0.025188 Validation acc: 0.993750\n",
      "Epoch: 808/1000 Iteration: 2425 Train loss: 0.001966 Train acc: 1.000000\n",
      "Epoch: 809/1000 Iteration: 2430 Train loss: 0.000778 Train acc: 1.000000\n",
      "Epoch: 809/1000 Iteration: 2430 Validation loss: 0.025773 Validation acc: 0.993750\n",
      "Epoch: 811/1000 Iteration: 2435 Train loss: 0.001688 Train acc: 1.000000\n",
      "Epoch: 813/1000 Iteration: 2440 Train loss: 0.001765 Train acc: 1.000000\n",
      "Epoch: 813/1000 Iteration: 2440 Validation loss: 0.026642 Validation acc: 0.992500\n",
      "Epoch: 814/1000 Iteration: 2445 Train loss: 0.001261 Train acc: 1.000000\n",
      "Epoch: 816/1000 Iteration: 2450 Train loss: 0.001203 Train acc: 1.000000\n",
      "Epoch: 816/1000 Iteration: 2450 Validation loss: 0.026951 Validation acc: 0.992500\n",
      "Epoch: 818/1000 Iteration: 2455 Train loss: 0.001382 Train acc: 1.000000\n",
      "Epoch: 819/1000 Iteration: 2460 Train loss: 0.001216 Train acc: 1.000000\n",
      "Epoch: 819/1000 Iteration: 2460 Validation loss: 0.026985 Validation acc: 0.992500\n",
      "Epoch: 821/1000 Iteration: 2465 Train loss: 0.001448 Train acc: 1.000000\n",
      "Epoch: 823/1000 Iteration: 2470 Train loss: 0.001002 Train acc: 1.000000\n",
      "Epoch: 823/1000 Iteration: 2470 Validation loss: 0.027231 Validation acc: 0.992500\n",
      "Epoch: 824/1000 Iteration: 2475 Train loss: 0.001212 Train acc: 1.000000\n",
      "Epoch: 826/1000 Iteration: 2480 Train loss: 0.001393 Train acc: 1.000000\n",
      "Epoch: 826/1000 Iteration: 2480 Validation loss: 0.026559 Validation acc: 0.993750\n",
      "Epoch: 828/1000 Iteration: 2485 Train loss: 0.001577 Train acc: 1.000000\n",
      "Epoch: 829/1000 Iteration: 2490 Train loss: 0.001855 Train acc: 1.000000\n",
      "Epoch: 829/1000 Iteration: 2490 Validation loss: 0.025965 Validation acc: 0.993750\n",
      "Epoch: 831/1000 Iteration: 2495 Train loss: 0.001208 Train acc: 1.000000\n",
      "Epoch: 833/1000 Iteration: 2500 Train loss: 0.001111 Train acc: 1.000000\n",
      "Epoch: 833/1000 Iteration: 2500 Validation loss: 0.026097 Validation acc: 0.993750\n",
      "Epoch: 834/1000 Iteration: 2505 Train loss: 0.000977 Train acc: 1.000000\n",
      "Epoch: 836/1000 Iteration: 2510 Train loss: 0.002149 Train acc: 1.000000\n",
      "Epoch: 836/1000 Iteration: 2510 Validation loss: 0.026016 Validation acc: 0.993750\n",
      "Epoch: 838/1000 Iteration: 2515 Train loss: 0.002799 Train acc: 1.000000\n",
      "Epoch: 839/1000 Iteration: 2520 Train loss: 0.001602 Train acc: 1.000000\n",
      "Epoch: 839/1000 Iteration: 2520 Validation loss: 0.025361 Validation acc: 0.993750\n",
      "Epoch: 841/1000 Iteration: 2525 Train loss: 0.001662 Train acc: 1.000000\n",
      "Epoch: 843/1000 Iteration: 2530 Train loss: 0.001769 Train acc: 1.000000\n",
      "Epoch: 843/1000 Iteration: 2530 Validation loss: 0.025292 Validation acc: 0.993750\n",
      "Epoch: 844/1000 Iteration: 2535 Train loss: 0.000922 Train acc: 1.000000\n",
      "Epoch: 846/1000 Iteration: 2540 Train loss: 0.001010 Train acc: 1.000000\n",
      "Epoch: 846/1000 Iteration: 2540 Validation loss: 0.025839 Validation acc: 0.993750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 848/1000 Iteration: 2545 Train loss: 0.001798 Train acc: 1.000000\n",
      "Epoch: 849/1000 Iteration: 2550 Train loss: 0.001180 Train acc: 1.000000\n",
      "Epoch: 849/1000 Iteration: 2550 Validation loss: 0.026337 Validation acc: 0.993750\n",
      "Epoch: 851/1000 Iteration: 2555 Train loss: 0.001218 Train acc: 1.000000\n",
      "Epoch: 853/1000 Iteration: 2560 Train loss: 0.005245 Train acc: 0.997500\n",
      "Epoch: 853/1000 Iteration: 2560 Validation loss: 0.025918 Validation acc: 0.993750\n",
      "Epoch: 854/1000 Iteration: 2565 Train loss: 0.001403 Train acc: 1.000000\n",
      "Epoch: 856/1000 Iteration: 2570 Train loss: 0.001073 Train acc: 1.000000\n",
      "Epoch: 856/1000 Iteration: 2570 Validation loss: 0.025107 Validation acc: 0.995000\n",
      "Epoch: 858/1000 Iteration: 2575 Train loss: 0.001805 Train acc: 1.000000\n",
      "Epoch: 859/1000 Iteration: 2580 Train loss: 0.000783 Train acc: 1.000000\n",
      "Epoch: 859/1000 Iteration: 2580 Validation loss: 0.025552 Validation acc: 0.993750\n",
      "Epoch: 861/1000 Iteration: 2585 Train loss: 0.001440 Train acc: 1.000000\n",
      "Epoch: 863/1000 Iteration: 2590 Train loss: 0.000936 Train acc: 1.000000\n",
      "Epoch: 863/1000 Iteration: 2590 Validation loss: 0.026360 Validation acc: 0.993750\n",
      "Epoch: 864/1000 Iteration: 2595 Train loss: 0.001584 Train acc: 1.000000\n",
      "Epoch: 866/1000 Iteration: 2600 Train loss: 0.001344 Train acc: 1.000000\n",
      "Epoch: 866/1000 Iteration: 2600 Validation loss: 0.026418 Validation acc: 0.993750\n",
      "Epoch: 868/1000 Iteration: 2605 Train loss: 0.001948 Train acc: 1.000000\n",
      "Epoch: 869/1000 Iteration: 2610 Train loss: 0.001151 Train acc: 1.000000\n",
      "Epoch: 869/1000 Iteration: 2610 Validation loss: 0.026324 Validation acc: 0.993750\n",
      "Epoch: 871/1000 Iteration: 2615 Train loss: 0.001505 Train acc: 1.000000\n",
      "Epoch: 873/1000 Iteration: 2620 Train loss: 0.001392 Train acc: 1.000000\n",
      "Epoch: 873/1000 Iteration: 2620 Validation loss: 0.026004 Validation acc: 0.993750\n",
      "Epoch: 874/1000 Iteration: 2625 Train loss: 0.001354 Train acc: 1.000000\n",
      "Epoch: 876/1000 Iteration: 2630 Train loss: 0.001662 Train acc: 1.000000\n",
      "Epoch: 876/1000 Iteration: 2630 Validation loss: 0.026373 Validation acc: 0.993750\n",
      "Epoch: 878/1000 Iteration: 2635 Train loss: 0.000852 Train acc: 1.000000\n",
      "Epoch: 879/1000 Iteration: 2640 Train loss: 0.000659 Train acc: 1.000000\n",
      "Epoch: 879/1000 Iteration: 2640 Validation loss: 0.025605 Validation acc: 0.992500\n",
      "Epoch: 881/1000 Iteration: 2645 Train loss: 0.000892 Train acc: 1.000000\n",
      "Epoch: 883/1000 Iteration: 2650 Train loss: 0.001988 Train acc: 1.000000\n",
      "Epoch: 883/1000 Iteration: 2650 Validation loss: 0.026012 Validation acc: 0.993750\n",
      "Epoch: 884/1000 Iteration: 2655 Train loss: 0.000713 Train acc: 1.000000\n",
      "Epoch: 886/1000 Iteration: 2660 Train loss: 0.000989 Train acc: 1.000000\n",
      "Epoch: 886/1000 Iteration: 2660 Validation loss: 0.026524 Validation acc: 0.995000\n",
      "Epoch: 888/1000 Iteration: 2665 Train loss: 0.001063 Train acc: 1.000000\n",
      "Epoch: 889/1000 Iteration: 2670 Train loss: 0.001001 Train acc: 1.000000\n",
      "Epoch: 889/1000 Iteration: 2670 Validation loss: 0.025778 Validation acc: 0.993750\n",
      "Epoch: 891/1000 Iteration: 2675 Train loss: 0.001136 Train acc: 1.000000\n",
      "Epoch: 893/1000 Iteration: 2680 Train loss: 0.001047 Train acc: 1.000000\n",
      "Epoch: 893/1000 Iteration: 2680 Validation loss: 0.025920 Validation acc: 0.993750\n",
      "Epoch: 894/1000 Iteration: 2685 Train loss: 0.000982 Train acc: 1.000000\n",
      "Epoch: 896/1000 Iteration: 2690 Train loss: 0.001360 Train acc: 1.000000\n",
      "Epoch: 896/1000 Iteration: 2690 Validation loss: 0.026131 Validation acc: 0.993750\n",
      "Epoch: 898/1000 Iteration: 2695 Train loss: 0.001718 Train acc: 1.000000\n",
      "Epoch: 899/1000 Iteration: 2700 Train loss: 0.001931 Train acc: 1.000000\n",
      "Epoch: 899/1000 Iteration: 2700 Validation loss: 0.027565 Validation acc: 0.992500\n",
      "Epoch: 901/1000 Iteration: 2705 Train loss: 0.001946 Train acc: 1.000000\n",
      "Epoch: 903/1000 Iteration: 2710 Train loss: 0.000946 Train acc: 1.000000\n",
      "Epoch: 903/1000 Iteration: 2710 Validation loss: 0.026126 Validation acc: 0.993750\n",
      "Epoch: 904/1000 Iteration: 2715 Train loss: 0.000649 Train acc: 1.000000\n",
      "Epoch: 906/1000 Iteration: 2720 Train loss: 0.000681 Train acc: 1.000000\n",
      "Epoch: 906/1000 Iteration: 2720 Validation loss: 0.025549 Validation acc: 0.993750\n",
      "Epoch: 908/1000 Iteration: 2725 Train loss: 0.001028 Train acc: 1.000000\n",
      "Epoch: 909/1000 Iteration: 2730 Train loss: 0.000924 Train acc: 1.000000\n",
      "Epoch: 909/1000 Iteration: 2730 Validation loss: 0.025879 Validation acc: 0.993750\n",
      "Epoch: 911/1000 Iteration: 2735 Train loss: 0.001716 Train acc: 1.000000\n",
      "Epoch: 913/1000 Iteration: 2740 Train loss: 0.001742 Train acc: 1.000000\n",
      "Epoch: 913/1000 Iteration: 2740 Validation loss: 0.026082 Validation acc: 0.993750\n",
      "Epoch: 914/1000 Iteration: 2745 Train loss: 0.001177 Train acc: 1.000000\n",
      "Epoch: 916/1000 Iteration: 2750 Train loss: 0.000780 Train acc: 1.000000\n",
      "Epoch: 916/1000 Iteration: 2750 Validation loss: 0.026391 Validation acc: 0.992500\n",
      "Epoch: 918/1000 Iteration: 2755 Train loss: 0.001069 Train acc: 1.000000\n",
      "Epoch: 919/1000 Iteration: 2760 Train loss: 0.001081 Train acc: 1.000000\n",
      "Epoch: 919/1000 Iteration: 2760 Validation loss: 0.025973 Validation acc: 0.992500\n",
      "Epoch: 921/1000 Iteration: 2765 Train loss: 0.001066 Train acc: 1.000000\n",
      "Epoch: 923/1000 Iteration: 2770 Train loss: 0.001119 Train acc: 1.000000\n",
      "Epoch: 923/1000 Iteration: 2770 Validation loss: 0.026350 Validation acc: 0.993750\n",
      "Epoch: 924/1000 Iteration: 2775 Train loss: 0.002291 Train acc: 1.000000\n",
      "Epoch: 926/1000 Iteration: 2780 Train loss: 0.000939 Train acc: 1.000000\n",
      "Epoch: 926/1000 Iteration: 2780 Validation loss: 0.026059 Validation acc: 0.993750\n",
      "Epoch: 928/1000 Iteration: 2785 Train loss: 0.001100 Train acc: 1.000000\n",
      "Epoch: 929/1000 Iteration: 2790 Train loss: 0.000625 Train acc: 1.000000\n",
      "Epoch: 929/1000 Iteration: 2790 Validation loss: 0.025939 Validation acc: 0.993750\n",
      "Epoch: 931/1000 Iteration: 2795 Train loss: 0.000669 Train acc: 1.000000\n",
      "Epoch: 933/1000 Iteration: 2800 Train loss: 0.001811 Train acc: 1.000000\n",
      "Epoch: 933/1000 Iteration: 2800 Validation loss: 0.025933 Validation acc: 0.993750\n",
      "Epoch: 934/1000 Iteration: 2805 Train loss: 0.000570 Train acc: 1.000000\n",
      "Epoch: 936/1000 Iteration: 2810 Train loss: 0.000797 Train acc: 1.000000\n",
      "Epoch: 936/1000 Iteration: 2810 Validation loss: 0.025567 Validation acc: 0.993750\n",
      "Epoch: 938/1000 Iteration: 2815 Train loss: 0.001068 Train acc: 1.000000\n",
      "Epoch: 939/1000 Iteration: 2820 Train loss: 0.000869 Train acc: 1.000000\n",
      "Epoch: 939/1000 Iteration: 2820 Validation loss: 0.025411 Validation acc: 0.993750\n",
      "Epoch: 941/1000 Iteration: 2825 Train loss: 0.001290 Train acc: 1.000000\n",
      "Epoch: 943/1000 Iteration: 2830 Train loss: 0.000900 Train acc: 1.000000\n",
      "Epoch: 943/1000 Iteration: 2830 Validation loss: 0.025595 Validation acc: 0.993750\n",
      "Epoch: 944/1000 Iteration: 2835 Train loss: 0.000555 Train acc: 1.000000\n",
      "Epoch: 946/1000 Iteration: 2840 Train loss: 0.000625 Train acc: 1.000000\n",
      "Epoch: 946/1000 Iteration: 2840 Validation loss: 0.025299 Validation acc: 0.993750\n",
      "Epoch: 948/1000 Iteration: 2845 Train loss: 0.002978 Train acc: 0.997500\n",
      "Epoch: 949/1000 Iteration: 2850 Train loss: 0.000601 Train acc: 1.000000\n",
      "Epoch: 949/1000 Iteration: 2850 Validation loss: 0.024941 Validation acc: 0.993750\n",
      "Epoch: 951/1000 Iteration: 2855 Train loss: 0.001026 Train acc: 1.000000\n",
      "Epoch: 953/1000 Iteration: 2860 Train loss: 0.001150 Train acc: 1.000000\n",
      "Epoch: 953/1000 Iteration: 2860 Validation loss: 0.024691 Validation acc: 0.993750\n",
      "Epoch: 954/1000 Iteration: 2865 Train loss: 0.000943 Train acc: 1.000000\n",
      "Epoch: 956/1000 Iteration: 2870 Train loss: 0.001716 Train acc: 1.000000\n",
      "Epoch: 956/1000 Iteration: 2870 Validation loss: 0.025015 Validation acc: 0.993750\n",
      "Epoch: 958/1000 Iteration: 2875 Train loss: 0.000857 Train acc: 1.000000\n",
      "Epoch: 959/1000 Iteration: 2880 Train loss: 0.000697 Train acc: 1.000000\n",
      "Epoch: 959/1000 Iteration: 2880 Validation loss: 0.025251 Validation acc: 0.993750\n",
      "Epoch: 961/1000 Iteration: 2885 Train loss: 0.001176 Train acc: 1.000000\n",
      "Epoch: 963/1000 Iteration: 2890 Train loss: 0.001057 Train acc: 1.000000\n",
      "Epoch: 963/1000 Iteration: 2890 Validation loss: 0.024880 Validation acc: 0.993750\n",
      "Epoch: 964/1000 Iteration: 2895 Train loss: 0.000774 Train acc: 1.000000\n",
      "Epoch: 966/1000 Iteration: 2900 Train loss: 0.001806 Train acc: 1.000000\n",
      "Epoch: 966/1000 Iteration: 2900 Validation loss: 0.025094 Validation acc: 0.993750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 968/1000 Iteration: 2905 Train loss: 0.000735 Train acc: 1.000000\n",
      "Epoch: 969/1000 Iteration: 2910 Train loss: 0.000999 Train acc: 1.000000\n",
      "Epoch: 969/1000 Iteration: 2910 Validation loss: 0.025553 Validation acc: 0.995000\n",
      "Epoch: 971/1000 Iteration: 2915 Train loss: 0.000821 Train acc: 1.000000\n",
      "Epoch: 973/1000 Iteration: 2920 Train loss: 0.001196 Train acc: 1.000000\n",
      "Epoch: 973/1000 Iteration: 2920 Validation loss: 0.024357 Validation acc: 0.993750\n",
      "Epoch: 974/1000 Iteration: 2925 Train loss: 0.000964 Train acc: 1.000000\n",
      "Epoch: 976/1000 Iteration: 2930 Train loss: 0.000692 Train acc: 1.000000\n",
      "Epoch: 976/1000 Iteration: 2930 Validation loss: 0.024450 Validation acc: 0.993750\n",
      "Epoch: 978/1000 Iteration: 2935 Train loss: 0.000789 Train acc: 1.000000\n",
      "Epoch: 979/1000 Iteration: 2940 Train loss: 0.000787 Train acc: 1.000000\n",
      "Epoch: 979/1000 Iteration: 2940 Validation loss: 0.025286 Validation acc: 0.993750\n",
      "Epoch: 981/1000 Iteration: 2945 Train loss: 0.000933 Train acc: 1.000000\n",
      "Epoch: 983/1000 Iteration: 2950 Train loss: 0.000756 Train acc: 1.000000\n",
      "Epoch: 983/1000 Iteration: 2950 Validation loss: 0.025500 Validation acc: 0.992500\n",
      "Epoch: 984/1000 Iteration: 2955 Train loss: 0.001018 Train acc: 1.000000\n",
      "Epoch: 986/1000 Iteration: 2960 Train loss: 0.000807 Train acc: 1.000000\n",
      "Epoch: 986/1000 Iteration: 2960 Validation loss: 0.025320 Validation acc: 0.992500\n",
      "Epoch: 988/1000 Iteration: 2965 Train loss: 0.001947 Train acc: 1.000000\n",
      "Epoch: 989/1000 Iteration: 2970 Train loss: 0.000722 Train acc: 1.000000\n",
      "Epoch: 989/1000 Iteration: 2970 Validation loss: 0.025284 Validation acc: 0.993750\n",
      "Epoch: 991/1000 Iteration: 2975 Train loss: 0.000816 Train acc: 1.000000\n",
      "Epoch: 993/1000 Iteration: 2980 Train loss: 0.001034 Train acc: 1.000000\n",
      "Epoch: 993/1000 Iteration: 2980 Validation loss: 0.025682 Validation acc: 0.993750\n",
      "Epoch: 994/1000 Iteration: 2985 Train loss: 0.000642 Train acc: 1.000000\n",
      "Epoch: 996/1000 Iteration: 2990 Train loss: 0.000751 Train acc: 1.000000\n",
      "Epoch: 996/1000 Iteration: 2990 Validation loss: 0.026232 Validation acc: 0.995000\n",
      "Epoch: 998/1000 Iteration: 2995 Train loss: 0.001004 Train acc: 1.000000\n",
      "Epoch: 999/1000 Iteration: 3000 Train loss: 0.000526 Train acc: 1.000000\n",
      "Epoch: 999/1000 Iteration: 3000 Validation loss: 0.025354 Validation acc: 0.993750\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn\n",
    "    \n",
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_train, y_train, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_valid, y_valid, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/mHealth.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints-cnn\\mHealth.ckpt\n",
      "Test accuracy: 0.992500\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
